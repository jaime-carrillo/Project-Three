{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tawnyn\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\tawnyn\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\tawnyn\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\tawnyn\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\tawnyn\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\tawnyn\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\tawnyn\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\tawnyn\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\tawnyn\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\tawnyn\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\tawnyn\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\tawnyn\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "# Dependencies\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow\n",
    "# tensorflow.keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Read in csv (already transformed)\n",
    "# df = pd.read_csv('..//..//data/hospitals/Display.csv')\n",
    "# df.replace(True, 1, inplace=True)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FAC_ZIP</th>\n",
       "      <th>FAC_PAR_CORP_ZIP</th>\n",
       "      <th>TRAUMA_CTR</th>\n",
       "      <th>TEACH_HOSP</th>\n",
       "      <th>TEACH_RURAL</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>HEALTH_SVC_AREA</th>\n",
       "      <th>LIC_CAT</th>\n",
       "      <th>LICEE_TOC</th>\n",
       "      <th>...</th>\n",
       "      <th>CARD_CATH_PED_IP_THER_VST</th>\n",
       "      <th>CARD_CATH_PED_OP_THER_VST</th>\n",
       "      <th>CARDIAC_CATHETERIZATION_ADULT_INPAT_THERAPEUTIC_VISITS</th>\n",
       "      <th>CARDIAC_CATHETERIZATION_ADULT_OUTPAT_THERAPEUTIC_VISITS</th>\n",
       "      <th>CARDIAC_CATHETERIZATION_THERAPEUTIC_VISITS_TOT</th>\n",
       "      <th>INPATIENT_AVG_PER_SURGERY</th>\n",
       "      <th>OUTPATIENT_AVG_PER_SURGERY</th>\n",
       "      <th>FAC_ACQUIRE_EQUIP_OVER_500K</th>\n",
       "      <th>Target</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>94501</td>\n",
       "      <td>94602</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-122.253991</td>\n",
       "      <td>37.76266</td>\n",
       "      <td>05</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>75.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.403166</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>94705</td>\n",
       "      <td>95833</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-122.257430</td>\n",
       "      <td>37.85645</td>\n",
       "      <td>05</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>127.6</td>\n",
       "      <td>75.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.226161</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>94609</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-122.267470</td>\n",
       "      <td>37.83722</td>\n",
       "      <td>05</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>22</td>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>137.4</td>\n",
       "      <td>70.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.608373</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>94578</td>\n",
       "      <td>94602</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-122.118190</td>\n",
       "      <td>37.70648</td>\n",
       "      <td>05</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>94704</td>\n",
       "      <td>95833</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-122.269840</td>\n",
       "      <td>37.86373</td>\n",
       "      <td>05</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 269 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   FAC_ZIP  FAC_PAR_CORP_ZIP  TRAUMA_CTR  TEACH_HOSP  TEACH_RURAL   LONGITUDE  \\\n",
       "0    94501             94602         1.0         0.0          0.0 -122.253991   \n",
       "1    94705             95833         1.0         0.0          0.0 -122.257430   \n",
       "2    94609                 0         1.0         0.0          0.0 -122.267470   \n",
       "3    94578             94602         1.0         0.0          0.0 -122.118190   \n",
       "4    94704             95833         1.0         0.0          0.0 -122.269840   \n",
       "\n",
       "   LATITUDE HEALTH_SVC_AREA  LIC_CAT  LICEE_TOC  ...  \\\n",
       "0  37.76266              05      1.0        0.0  ...   \n",
       "1  37.85645              05      1.0        1.0  ...   \n",
       "2  37.83722              05      1.0        1.0  ...   \n",
       "3  37.70648              05      1.0        0.0  ...   \n",
       "4  37.86373              05      1.0        1.0  ...   \n",
       "\n",
       "   CARD_CATH_PED_IP_THER_VST  CARD_CATH_PED_OP_THER_VST  \\\n",
       "0                          0                          0   \n",
       "1                          0                          0   \n",
       "2                         22                         35   \n",
       "3                          0                          0   \n",
       "4                          0                          0   \n",
       "\n",
       "   CARDIAC_CATHETERIZATION_ADULT_INPAT_THERAPEUTIC_VISITS  \\\n",
       "0                                                  0        \n",
       "1                                                  0        \n",
       "2                                                  2        \n",
       "3                                                  0        \n",
       "4                                                  0        \n",
       "\n",
       "   CARDIAC_CATHETERIZATION_ADULT_OUTPAT_THERAPEUTIC_VISITS  \\\n",
       "0                                                  0         \n",
       "1                                                  0         \n",
       "2                                                  1         \n",
       "3                                                  0         \n",
       "4                                                  0         \n",
       "\n",
       "   CARDIAC_CATHETERIZATION_THERAPEUTIC_VISITS_TOT  INPATIENT_AVG_PER_SURGERY  \\\n",
       "0                                               0                      105.0   \n",
       "1                                               0                      127.6   \n",
       "2                                              60                      137.4   \n",
       "3                                               0                        0.0   \n",
       "4                                               0                        0.0   \n",
       "\n",
       "   OUTPATIENT_AVG_PER_SURGERY  FAC_ACQUIRE_EQUIP_OVER_500K    Target  Label  \n",
       "0                        75.2                          1.0  0.403166    1.0  \n",
       "1                        75.8                          1.0  0.226161    0.0  \n",
       "2                        70.8                          0.0  0.608373    1.0  \n",
       "3                         0.0                          0.0  0.000000    0.0  \n",
       "4                         0.0                          0.0  0.000000    0.0  \n",
       "\n",
       "[5 rows x 269 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in csv (already transformed)\n",
    "hosp_df = pd.read_csv('..//..//data/hospitals/hosp19_util_data_prelim.csv')\n",
    "\n",
    "# Drop columns not need for modeling\n",
    "df = hosp_df.drop(['Description', 'FAC_NO', 'FAC_NAME','FAC_STR_ADDR','FAC_CITY','FAC_PHONE','FAC_ADMIN_NAME','FAC_OPERATED_THIS_YR','FAC_OP_PER_BEGIN_DT','FAC_OP_PER_END_DT','FAC_PAR_CORP_NAME','FAC_PAR_CORP_BUS_ADDR','FAC_PAR_CORP_CITY','FAC_PAR_CORP_STATE','REPT_PREP_NAME','SUBMITTED_DT','REV_REPT_PREP_NAME','REVISED_DT','CORRECTED_DT','LICENSE_NO','LICENSE_EFF_DATE','LICENSE_EXP_DATE','LICENSE_STATUS','FACILITY_LEVEL','ASSEMBLY_DIST','SENATE_DIST','CONGRESS_DIST','CENS_TRACT','MED_SVC_STUDY_AREA','LA_COUNTY_SVC_PLAN_AREA','COUNTY'], axis=1)\n",
    "# ,'RURAL_HEALTH_CLINIC']\n",
    "\n",
    "# Format Categorical Data\n",
    "df.TEACH_HOSP = df.TEACH_HOSP != \"No\"\n",
    "df.TEACH_RURAL = df.TEACH_RURAL != \"No\"\n",
    "df.TRAUMA_CTR = df.TRAUMA_CTR != 0\n",
    "df.HEALTH_SVC_AREA = df.HEALTH_SVC_AREA.str[:2]\n",
    "df.LIC_CAT = df.LIC_CAT == \"General Acute Care Hospital\"\n",
    "df.LICEE_TOC = df.LICEE_TOC == \"Non-Profit Corporation (including church-related)\"\n",
    "df.PRIN_SERVICE_TYPE = df.PRIN_SERVICE_TYPE == \"General Medical / Surgical\"\n",
    "df.FAC_ACQUIRE_EQUIP_OVER_500K = df.FAC_ACQUIRE_EQUIP_OVER_500K != \"No\"\n",
    "df.OFFER_ALTERNATE_BIRTH_PROG = df.OFFER_ALTERNATE_BIRTH_PROG != \"No\"\n",
    "df.LIC_CARDIOLOGY_CARDIOVASCULAR_SURG_SERVICES = df.LIC_CARDIOLOGY_CARDIOVASCULAR_SURG_SERVICES != 0\n",
    "df.OFFER_AMBULATORY_SURG_PROG = df.OFFER_AMBULATORY_SURG_PROG != \"No\"\n",
    "df.LIC_ED_LEV_END = df.LIC_ED_LEV_END != 0\n",
    "df.EMSA_TRAUMA_DESIGNATION_PEDIATRIC = df.EMSA_TRAUMA_DESIGNATION_PEDIATRIC != 0\n",
    "df.EMER_DEPT_AMBULANCE_DIVERSION_HOURS = df.EMER_DEPT_AMBULANCE_DIVERSION_HOURS != \"No\"\n",
    "df.LIC_ED_LEV_BEGIN = df.LIC_ED_LEV_BEGIN != 0\n",
    "df.EMSA_TRAUMA_DESIGNATION = df.EMSA_TRAUMA_DESIGNATION != 0\n",
    "df.OUTPATIENT_PALLIATIVE_CARE_SERV_OFFERED = df.OUTPATIENT_PALLIATIVE_CARE_SERV_OFFERED != 0\n",
    "df.INPATIENT_PALLIATIVE_CARE_PROG_OFFERED = df.INPATIENT_PALLIATIVE_CARE_PROG_OFFERED != 0\n",
    "df.INPATIENT_HOSPICE_PROG_OFFERED = df.INPATIENT_HOSPICE_PROG_OFFERED != 0\n",
    "df.SHORT_DOYLE_SERVICES_OFFERED = df.SHORT_DOYLE_SERVICES_OFFERED != 0\n",
    "\n",
    "\n",
    "# df.PRIMARY_NON_ENGLISH_LANG = df.PRIMARY_NON_ENGLISH_LANG == \"Spanish\"\n",
    "df.replace(True, 1, inplace=True)\n",
    "\n",
    "# Drop final coloumns\n",
    "df.drop(df.iloc[:, 267:323], inplace=True, axis=1)\n",
    "\n",
    "# Fill in all blanks with 0 (for deep learning)\n",
    "df = df.fillna(0)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FAC_ZIP</th>\n",
       "      <th>FAC_PAR_CORP_ZIP</th>\n",
       "      <th>TRAUMA_CTR</th>\n",
       "      <th>TEACH_HOSP</th>\n",
       "      <th>TEACH_RURAL</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>HEALTH_SVC_AREA</th>\n",
       "      <th>LIC_CAT</th>\n",
       "      <th>LICEE_TOC</th>\n",
       "      <th>...</th>\n",
       "      <th>CARDIOVASCULAR_SURG_OPER_ADULT_BYPASS_NOT_USED</th>\n",
       "      <th>CARDIOVASCULAR_SURG_OPER_BYPASS_NOT_USED_TOT</th>\n",
       "      <th>CARD_CATH_PED_IP_THER_VST</th>\n",
       "      <th>CARD_CATH_PED_OP_THER_VST</th>\n",
       "      <th>CARDIAC_CATHETERIZATION_ADULT_INPAT_THERAPEUTIC_VISITS</th>\n",
       "      <th>CARDIAC_CATHETERIZATION_ADULT_OUTPAT_THERAPEUTIC_VISITS</th>\n",
       "      <th>CARDIAC_CATHETERIZATION_THERAPEUTIC_VISITS_TOT</th>\n",
       "      <th>INPATIENT_AVG_PER_SURGERY</th>\n",
       "      <th>OUTPATIENT_AVG_PER_SURGERY</th>\n",
       "      <th>FAC_ACQUIRE_EQUIP_OVER_500K</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>94501.0</td>\n",
       "      <td>94602</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-122.253991</td>\n",
       "      <td>37.762660</td>\n",
       "      <td>05</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>75.2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>94705.0</td>\n",
       "      <td>95833</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-122.257430</td>\n",
       "      <td>37.856450</td>\n",
       "      <td>05</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>127.6</td>\n",
       "      <td>75.8</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>94609.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-122.267470</td>\n",
       "      <td>37.837220</td>\n",
       "      <td>05</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>34</td>\n",
       "      <td>22</td>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>137.4</td>\n",
       "      <td>70.8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>94578.0</td>\n",
       "      <td>94602</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-122.118190</td>\n",
       "      <td>37.706480</td>\n",
       "      <td>05</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>94704.0</td>\n",
       "      <td>95833</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-122.269840</td>\n",
       "      <td>37.863730</td>\n",
       "      <td>05</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>95901.0</td>\n",
       "      <td>95991</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-121.593602</td>\n",
       "      <td>39.138805</td>\n",
       "      <td>02</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>89</td>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>369</td>\n",
       "      <td>358</td>\n",
       "      <td>727</td>\n",
       "      <td>145.5</td>\n",
       "      <td>84.8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>93703.0</td>\n",
       "      <td>93611</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-119.779521</td>\n",
       "      <td>36.778140</td>\n",
       "      <td>09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>93940.0</td>\n",
       "      <td>93940</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-121.892428</td>\n",
       "      <td>36.580786</td>\n",
       "      <td>08</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>95023.0</td>\n",
       "      <td>95023</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-121.386700</td>\n",
       "      <td>36.835140</td>\n",
       "      <td>08</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>478 rows × 265 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     FAC_ZIP  FAC_PAR_CORP_ZIP  TRAUMA_CTR  TEACH_HOSP  TEACH_RURAL  \\\n",
       "0    94501.0             94602         1.0         0.0          0.0   \n",
       "1    94705.0             95833         1.0         0.0          0.0   \n",
       "2    94609.0                 0         1.0         0.0          0.0   \n",
       "3    94578.0             94602         1.0         0.0          0.0   \n",
       "4    94704.0             95833         1.0         0.0          0.0   \n",
       "..       ...               ...         ...         ...          ...   \n",
       "473  95901.0             95991         1.0         0.0          0.0   \n",
       "474  93703.0             93611         1.0         0.0          0.0   \n",
       "475  93940.0             93940         1.0         0.0          0.0   \n",
       "476  95023.0             95023         1.0         0.0          0.0   \n",
       "477      0.0                 0         1.0         1.0          1.0   \n",
       "\n",
       "      LONGITUDE   LATITUDE HEALTH_SVC_AREA  LIC_CAT  LICEE_TOC  ...  \\\n",
       "0   -122.253991  37.762660              05      1.0        0.0  ...   \n",
       "1   -122.257430  37.856450              05      1.0        1.0  ...   \n",
       "2   -122.267470  37.837220              05      1.0        1.0  ...   \n",
       "3   -122.118190  37.706480              05      1.0        0.0  ...   \n",
       "4   -122.269840  37.863730              05      1.0        1.0  ...   \n",
       "..          ...        ...             ...      ...        ...  ...   \n",
       "473 -121.593602  39.138805              02      1.0        1.0  ...   \n",
       "474 -119.779521  36.778140              09      1.0        1.0  ...   \n",
       "475 -121.892428  36.580786              08      1.0        1.0  ...   \n",
       "476 -121.386700  36.835140              08      1.0        0.0  ...   \n",
       "477    0.000000   0.000000               0      0.0        0.0  ...   \n",
       "\n",
       "     CARDIOVASCULAR_SURG_OPER_ADULT_BYPASS_NOT_USED  \\\n",
       "0                                                 0   \n",
       "1                                                 0   \n",
       "2                                                 3   \n",
       "3                                                 0   \n",
       "4                                                 0   \n",
       "..                                              ...   \n",
       "473                                              89   \n",
       "474                                               0   \n",
       "475                                               0   \n",
       "476                                               0   \n",
       "477                                               0   \n",
       "\n",
       "     CARDIOVASCULAR_SURG_OPER_BYPASS_NOT_USED_TOT  CARD_CATH_PED_IP_THER_VST  \\\n",
       "0                                               0                          0   \n",
       "1                                               0                          0   \n",
       "2                                              34                         22   \n",
       "3                                               0                          0   \n",
       "4                                               0                          0   \n",
       "..                                            ...                        ...   \n",
       "473                                            89                          0   \n",
       "474                                             0                          0   \n",
       "475                                             0                          0   \n",
       "476                                             0                          0   \n",
       "477                                             0                          0   \n",
       "\n",
       "     CARD_CATH_PED_OP_THER_VST  \\\n",
       "0                            0   \n",
       "1                            0   \n",
       "2                           35   \n",
       "3                            0   \n",
       "4                            0   \n",
       "..                         ...   \n",
       "473                          0   \n",
       "474                          0   \n",
       "475                          0   \n",
       "476                          0   \n",
       "477                          0   \n",
       "\n",
       "     CARDIAC_CATHETERIZATION_ADULT_INPAT_THERAPEUTIC_VISITS  \\\n",
       "0                                                    0        \n",
       "1                                                    0        \n",
       "2                                                    2        \n",
       "3                                                    0        \n",
       "4                                                    0        \n",
       "..                                                 ...        \n",
       "473                                                369        \n",
       "474                                                  0        \n",
       "475                                                  0        \n",
       "476                                                  0        \n",
       "477                                                  0        \n",
       "\n",
       "     CARDIAC_CATHETERIZATION_ADULT_OUTPAT_THERAPEUTIC_VISITS  \\\n",
       "0                                                    0         \n",
       "1                                                    0         \n",
       "2                                                    1         \n",
       "3                                                    0         \n",
       "4                                                    0         \n",
       "..                                                 ...         \n",
       "473                                                358         \n",
       "474                                                  0         \n",
       "475                                                  0         \n",
       "476                                                  0         \n",
       "477                                                  0         \n",
       "\n",
       "     CARDIAC_CATHETERIZATION_THERAPEUTIC_VISITS_TOT  \\\n",
       "0                                                 0   \n",
       "1                                                 0   \n",
       "2                                                60   \n",
       "3                                                 0   \n",
       "4                                                 0   \n",
       "..                                              ...   \n",
       "473                                             727   \n",
       "474                                               0   \n",
       "475                                               0   \n",
       "476                                               0   \n",
       "477                                               0   \n",
       "\n",
       "     INPATIENT_AVG_PER_SURGERY  OUTPATIENT_AVG_PER_SURGERY  \\\n",
       "0                        105.0                        75.2   \n",
       "1                        127.6                        75.8   \n",
       "2                        137.4                        70.8   \n",
       "3                          0.0                         0.0   \n",
       "4                          0.0                         0.0   \n",
       "..                         ...                         ...   \n",
       "473                      145.5                        84.8   \n",
       "474                        0.0                         0.0   \n",
       "475                        0.0                         0.0   \n",
       "476                        0.0                         0.0   \n",
       "477                        0.0                         0.0   \n",
       "\n",
       "     FAC_ACQUIRE_EQUIP_OVER_500K  \n",
       "0                            1.0  \n",
       "1                            1.0  \n",
       "2                            0.0  \n",
       "3                            0.0  \n",
       "4                            0.0  \n",
       "..                           ...  \n",
       "473                          0.0  \n",
       "474                          0.0  \n",
       "475                          0.0  \n",
       "476                          0.0  \n",
       "477                          1.0  \n",
       "\n",
       "[478 rows x 265 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrive all possible inputs\n",
    "features = df.drop([\"EMER_DEPT_VISITS_NOT_RESULT_ADMISSIONS_TOT\", \"ER_TRAFFIC_TOT\",\"Target\",\"Label\"], axis=1) #df.iloc[:, 0:267]\n",
    "features\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-86a9e3212f200d21",
     "locked": false,
     "schema_version": 1,
     "solution": true
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(478, 265) (478,)\n"
     ]
    }
   ],
   "source": [
    "# Define X and y\n",
    "X = features\n",
    "y = df[\"Label\"]\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-711a82d9b32c83ff",
     "locked": false,
     "schema_version": 1,
     "solution": true
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.33, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-711a82d9b32c83ff",
     "locked": false,
     "schema_version": 1,
     "solution": true
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "X_scaler = MinMaxScaler().fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-711a82d9b32c83ff",
     "locked": false,
     "schema_version": 1,
     "solution": true
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# # Step 1: Label-encode data set\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "encoded_y_train = label_encoder.transform(y_train)\n",
    "encoded_y_test = label_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-711a82d9b32c83ff",
     "locked": false,
     "schema_version": 1,
     "solution": true
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# # Step 2: Convert encoded labels to one-hot-encoding\n",
    "y_train_categorical = to_categorical(encoded_y_train)\n",
    "y_test_categorical = to_categorical(encoded_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Deep Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\tawnyn\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "# Create model and add layers\n",
    "model = Sequential()\n",
    "model.add(Dense(units=100, activation='relu', input_dim=265))\n",
    "model.add(Dense(units=100, activation='relu'))\n",
    "model.add(Dense(units=100, activation='relu'))\n",
    "model.add(Dense(units=2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.metrics.CategoricalAccuracy at 0x1c94e0558c8>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensorflow.keras.metrics.CategoricalAccuracy(\n",
    "    name='categorical_accuracy', dtype=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile and fit the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "#               metrics=[tf.keras.metrics.CategoricalAccuracy()])\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 100)               26600     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 47,002\n",
      "Trainable params: 47,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 320 samples, validate on 158 samples\n",
      "Epoch 1/500\n",
      "320/320 - 0s - loss: 0.6785 - acc: 0.5656 - val_loss: 0.6011 - val_acc: 0.6646\n",
      "Epoch 2/500\n",
      "320/320 - 0s - loss: 0.5739 - acc: 0.7094 - val_loss: 0.4975 - val_acc: 0.8228\n",
      "Epoch 3/500\n",
      "320/320 - 0s - loss: 0.4464 - acc: 0.8438 - val_loss: 0.3883 - val_acc: 0.8544\n",
      "Epoch 4/500\n",
      "320/320 - 0s - loss: 0.3428 - acc: 0.8719 - val_loss: 0.3396 - val_acc: 0.8861\n",
      "Epoch 5/500\n",
      "320/320 - 0s - loss: 0.2836 - acc: 0.8750 - val_loss: 0.3347 - val_acc: 0.8608\n",
      "Epoch 6/500\n",
      "320/320 - 0s - loss: 0.2326 - acc: 0.9031 - val_loss: 0.3309 - val_acc: 0.8481\n",
      "Epoch 7/500\n",
      "320/320 - 0s - loss: 0.2138 - acc: 0.9125 - val_loss: 0.3580 - val_acc: 0.8481\n",
      "Epoch 8/500\n",
      "320/320 - 0s - loss: 0.1975 - acc: 0.9219 - val_loss: 0.4389 - val_acc: 0.7911\n",
      "Epoch 9/500\n",
      "320/320 - 0s - loss: 0.1584 - acc: 0.9375 - val_loss: 0.3756 - val_acc: 0.8354\n",
      "Epoch 10/500\n",
      "320/320 - 0s - loss: 0.1339 - acc: 0.9656 - val_loss: 0.3646 - val_acc: 0.8544\n",
      "Epoch 11/500\n",
      "320/320 - 0s - loss: 0.1074 - acc: 0.9781 - val_loss: 0.3778 - val_acc: 0.8734\n",
      "Epoch 12/500\n",
      "320/320 - 0s - loss: 0.0911 - acc: 0.9781 - val_loss: 0.4201 - val_acc: 0.8418\n",
      "Epoch 13/500\n",
      "320/320 - 0s - loss: 0.0701 - acc: 0.9875 - val_loss: 0.4320 - val_acc: 0.8544\n",
      "Epoch 14/500\n",
      "320/320 - 0s - loss: 0.0587 - acc: 0.9906 - val_loss: 0.5234 - val_acc: 0.8228\n",
      "Epoch 15/500\n",
      "320/320 - 0s - loss: 0.0489 - acc: 0.9937 - val_loss: 0.5662 - val_acc: 0.8291\n",
      "Epoch 16/500\n",
      "320/320 - 0s - loss: 0.0476 - acc: 0.9906 - val_loss: 0.5289 - val_acc: 0.8481\n",
      "Epoch 17/500\n",
      "320/320 - 0s - loss: 0.0491 - acc: 0.9781 - val_loss: 0.5398 - val_acc: 0.8291\n",
      "Epoch 18/500\n",
      "320/320 - 0s - loss: 0.0677 - acc: 0.9688 - val_loss: 0.5114 - val_acc: 0.8354\n",
      "Epoch 19/500\n",
      "320/320 - 0s - loss: 0.0392 - acc: 0.9969 - val_loss: 0.5370 - val_acc: 0.8354\n",
      "Epoch 20/500\n",
      "320/320 - 0s - loss: 0.0326 - acc: 0.9969 - val_loss: 0.7573 - val_acc: 0.8165\n",
      "Epoch 21/500\n",
      "320/320 - 0s - loss: 0.0312 - acc: 0.9906 - val_loss: 0.5692 - val_acc: 0.8418\n",
      "Epoch 22/500\n",
      "320/320 - 0s - loss: 0.0153 - acc: 0.9969 - val_loss: 0.6160 - val_acc: 0.8418\n",
      "Epoch 23/500\n",
      "320/320 - 0s - loss: 0.0077 - acc: 1.0000 - val_loss: 0.6877 - val_acc: 0.8228\n",
      "Epoch 24/500\n",
      "320/320 - 0s - loss: 0.0056 - acc: 1.0000 - val_loss: 0.6649 - val_acc: 0.8481\n",
      "Epoch 25/500\n",
      "320/320 - 0s - loss: 0.0042 - acc: 1.0000 - val_loss: 0.6687 - val_acc: 0.8544\n",
      "Epoch 26/500\n",
      "320/320 - 0s - loss: 0.0032 - acc: 1.0000 - val_loss: 0.7243 - val_acc: 0.8544\n",
      "Epoch 27/500\n",
      "320/320 - 0s - loss: 0.0027 - acc: 1.0000 - val_loss: 0.7308 - val_acc: 0.8608\n",
      "Epoch 28/500\n",
      "320/320 - 0s - loss: 0.0024 - acc: 1.0000 - val_loss: 0.7440 - val_acc: 0.8544\n",
      "Epoch 29/500\n",
      "320/320 - 0s - loss: 0.0021 - acc: 1.0000 - val_loss: 0.7635 - val_acc: 0.8481\n",
      "Epoch 30/500\n",
      "320/320 - 0s - loss: 0.0019 - acc: 1.0000 - val_loss: 0.7659 - val_acc: 0.8481\n",
      "Epoch 31/500\n",
      "320/320 - 0s - loss: 0.0018 - acc: 1.0000 - val_loss: 0.7695 - val_acc: 0.8544\n",
      "Epoch 32/500\n",
      "320/320 - 0s - loss: 0.0017 - acc: 1.0000 - val_loss: 0.8033 - val_acc: 0.8481\n",
      "Epoch 33/500\n",
      "320/320 - 0s - loss: 0.0014 - acc: 1.0000 - val_loss: 0.7865 - val_acc: 0.8544\n",
      "Epoch 34/500\n",
      "320/320 - 0s - loss: 0.0013 - acc: 1.0000 - val_loss: 0.8265 - val_acc: 0.8418\n",
      "Epoch 35/500\n",
      "320/320 - 0s - loss: 0.0011 - acc: 1.0000 - val_loss: 0.8403 - val_acc: 0.8418\n",
      "Epoch 36/500\n",
      "320/320 - 0s - loss: 9.8956e-04 - acc: 1.0000 - val_loss: 0.8401 - val_acc: 0.8481\n",
      "Epoch 37/500\n",
      "320/320 - 0s - loss: 8.9228e-04 - acc: 1.0000 - val_loss: 0.8587 - val_acc: 0.8481\n",
      "Epoch 38/500\n",
      "320/320 - 0s - loss: 8.0947e-04 - acc: 1.0000 - val_loss: 0.8728 - val_acc: 0.8481\n",
      "Epoch 39/500\n",
      "320/320 - 0s - loss: 7.2450e-04 - acc: 1.0000 - val_loss: 0.8989 - val_acc: 0.8418\n",
      "Epoch 40/500\n",
      "320/320 - 0s - loss: 6.6120e-04 - acc: 1.0000 - val_loss: 0.8977 - val_acc: 0.8481\n",
      "Epoch 41/500\n",
      "320/320 - 0s - loss: 5.9051e-04 - acc: 1.0000 - val_loss: 0.9143 - val_acc: 0.8418\n",
      "Epoch 42/500\n",
      "320/320 - 0s - loss: 5.3887e-04 - acc: 1.0000 - val_loss: 0.9295 - val_acc: 0.8418\n",
      "Epoch 43/500\n",
      "320/320 - 0s - loss: 5.0313e-04 - acc: 1.0000 - val_loss: 0.9459 - val_acc: 0.8418\n",
      "Epoch 44/500\n",
      "320/320 - 0s - loss: 4.5970e-04 - acc: 1.0000 - val_loss: 0.9413 - val_acc: 0.8544\n",
      "Epoch 45/500\n",
      "320/320 - 0s - loss: 4.2327e-04 - acc: 1.0000 - val_loss: 0.9625 - val_acc: 0.8418\n",
      "Epoch 46/500\n",
      "320/320 - 0s - loss: 3.8463e-04 - acc: 1.0000 - val_loss: 0.9809 - val_acc: 0.8418\n",
      "Epoch 47/500\n",
      "320/320 - 0s - loss: 3.6156e-04 - acc: 1.0000 - val_loss: 0.9904 - val_acc: 0.8418\n",
      "Epoch 48/500\n",
      "320/320 - 0s - loss: 3.2857e-04 - acc: 1.0000 - val_loss: 0.9874 - val_acc: 0.8481\n",
      "Epoch 49/500\n",
      "320/320 - 0s - loss: 3.1009e-04 - acc: 1.0000 - val_loss: 1.0005 - val_acc: 0.8481\n",
      "Epoch 50/500\n",
      "320/320 - 0s - loss: 2.8688e-04 - acc: 1.0000 - val_loss: 1.0186 - val_acc: 0.8418\n",
      "Epoch 51/500\n",
      "320/320 - 0s - loss: 2.6688e-04 - acc: 1.0000 - val_loss: 1.0275 - val_acc: 0.8418\n",
      "Epoch 52/500\n",
      "320/320 - 0s - loss: 2.5273e-04 - acc: 1.0000 - val_loss: 1.0326 - val_acc: 0.8481\n",
      "Epoch 53/500\n",
      "320/320 - 0s - loss: 2.3434e-04 - acc: 1.0000 - val_loss: 1.0431 - val_acc: 0.8481\n",
      "Epoch 54/500\n",
      "320/320 - 0s - loss: 2.2147e-04 - acc: 1.0000 - val_loss: 1.0510 - val_acc: 0.8481\n",
      "Epoch 55/500\n",
      "320/320 - 0s - loss: 2.1157e-04 - acc: 1.0000 - val_loss: 1.0538 - val_acc: 0.8481\n",
      "Epoch 56/500\n",
      "320/320 - 0s - loss: 1.9591e-04 - acc: 1.0000 - val_loss: 1.0740 - val_acc: 0.8418\n",
      "Epoch 57/500\n",
      "320/320 - 0s - loss: 1.8588e-04 - acc: 1.0000 - val_loss: 1.0825 - val_acc: 0.8418\n",
      "Epoch 58/500\n",
      "320/320 - 0s - loss: 1.7287e-04 - acc: 1.0000 - val_loss: 1.0844 - val_acc: 0.8481\n",
      "Epoch 59/500\n",
      "320/320 - 0s - loss: 1.6558e-04 - acc: 1.0000 - val_loss: 1.0889 - val_acc: 0.8481\n",
      "Epoch 60/500\n",
      "320/320 - 0s - loss: 1.5620e-04 - acc: 1.0000 - val_loss: 1.0984 - val_acc: 0.8481\n",
      "Epoch 61/500\n",
      "320/320 - 0s - loss: 1.4864e-04 - acc: 1.0000 - val_loss: 1.1044 - val_acc: 0.8481\n",
      "Epoch 62/500\n",
      "320/320 - 0s - loss: 1.4052e-04 - acc: 1.0000 - val_loss: 1.1156 - val_acc: 0.8481\n",
      "Epoch 63/500\n",
      "320/320 - 0s - loss: 1.3400e-04 - acc: 1.0000 - val_loss: 1.1234 - val_acc: 0.8481\n",
      "Epoch 64/500\n",
      "320/320 - 0s - loss: 1.2989e-04 - acc: 1.0000 - val_loss: 1.1326 - val_acc: 0.8481\n",
      "Epoch 65/500\n",
      "320/320 - 0s - loss: 1.2201e-04 - acc: 1.0000 - val_loss: 1.1320 - val_acc: 0.8481\n",
      "Epoch 66/500\n",
      "320/320 - 0s - loss: 1.1587e-04 - acc: 1.0000 - val_loss: 1.1390 - val_acc: 0.8481\n",
      "Epoch 67/500\n",
      "320/320 - 0s - loss: 1.1091e-04 - acc: 1.0000 - val_loss: 1.1489 - val_acc: 0.8481\n",
      "Epoch 68/500\n",
      "320/320 - 0s - loss: 1.0634e-04 - acc: 1.0000 - val_loss: 1.1551 - val_acc: 0.8481\n",
      "Epoch 69/500\n",
      "320/320 - 0s - loss: 1.0169e-04 - acc: 1.0000 - val_loss: 1.1646 - val_acc: 0.8481\n",
      "Epoch 70/500\n",
      "320/320 - 0s - loss: 9.6872e-05 - acc: 1.0000 - val_loss: 1.1696 - val_acc: 0.8481\n",
      "Epoch 71/500\n",
      "320/320 - 0s - loss: 9.3189e-05 - acc: 1.0000 - val_loss: 1.1740 - val_acc: 0.8481\n",
      "Epoch 72/500\n",
      "320/320 - 0s - loss: 8.9472e-05 - acc: 1.0000 - val_loss: 1.1785 - val_acc: 0.8481\n",
      "Epoch 73/500\n",
      "320/320 - 0s - loss: 8.6039e-05 - acc: 1.0000 - val_loss: 1.1872 - val_acc: 0.8481\n",
      "Epoch 74/500\n",
      "320/320 - 0s - loss: 8.2715e-05 - acc: 1.0000 - val_loss: 1.1912 - val_acc: 0.8481\n",
      "Epoch 75/500\n",
      "320/320 - 0s - loss: 7.9154e-05 - acc: 1.0000 - val_loss: 1.1963 - val_acc: 0.8481\n",
      "Epoch 76/500\n",
      "320/320 - 0s - loss: 7.6375e-05 - acc: 1.0000 - val_loss: 1.2033 - val_acc: 0.8481\n",
      "Epoch 77/500\n",
      "320/320 - 0s - loss: 7.3934e-05 - acc: 1.0000 - val_loss: 1.2061 - val_acc: 0.8481\n",
      "Epoch 78/500\n",
      "320/320 - 0s - loss: 7.0713e-05 - acc: 1.0000 - val_loss: 1.2143 - val_acc: 0.8481\n",
      "Epoch 79/500\n",
      "320/320 - 0s - loss: 6.8200e-05 - acc: 1.0000 - val_loss: 1.2210 - val_acc: 0.8481\n",
      "Epoch 80/500\n",
      "320/320 - 0s - loss: 6.5785e-05 - acc: 1.0000 - val_loss: 1.2267 - val_acc: 0.8481\n",
      "Epoch 81/500\n",
      "320/320 - 0s - loss: 6.3686e-05 - acc: 1.0000 - val_loss: 1.2293 - val_acc: 0.8481\n",
      "Epoch 82/500\n",
      "320/320 - 0s - loss: 6.2226e-05 - acc: 1.0000 - val_loss: 1.2394 - val_acc: 0.8481\n",
      "Epoch 83/500\n",
      "320/320 - 0s - loss: 6.0149e-05 - acc: 1.0000 - val_loss: 1.2383 - val_acc: 0.8481\n",
      "Epoch 84/500\n",
      "320/320 - 0s - loss: 5.7502e-05 - acc: 1.0000 - val_loss: 1.2462 - val_acc: 0.8481\n",
      "Epoch 85/500\n",
      "320/320 - 0s - loss: 5.5518e-05 - acc: 1.0000 - val_loss: 1.2509 - val_acc: 0.8481\n",
      "Epoch 86/500\n",
      "320/320 - 0s - loss: 5.3849e-05 - acc: 1.0000 - val_loss: 1.2546 - val_acc: 0.8481\n",
      "Epoch 87/500\n",
      "320/320 - 0s - loss: 5.2057e-05 - acc: 1.0000 - val_loss: 1.2617 - val_acc: 0.8481\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88/500\n",
      "320/320 - 0s - loss: 5.0468e-05 - acc: 1.0000 - val_loss: 1.2662 - val_acc: 0.8481\n",
      "Epoch 89/500\n",
      "320/320 - 0s - loss: 4.8947e-05 - acc: 1.0000 - val_loss: 1.2717 - val_acc: 0.8481\n",
      "Epoch 90/500\n",
      "320/320 - 0s - loss: 4.7611e-05 - acc: 1.0000 - val_loss: 1.2765 - val_acc: 0.8481\n",
      "Epoch 91/500\n",
      "320/320 - 0s - loss: 4.6836e-05 - acc: 1.0000 - val_loss: 1.2756 - val_acc: 0.8481\n",
      "Epoch 92/500\n",
      "320/320 - 0s - loss: 4.4781e-05 - acc: 1.0000 - val_loss: 1.2835 - val_acc: 0.8481\n",
      "Epoch 93/500\n",
      "320/320 - 0s - loss: 4.3795e-05 - acc: 1.0000 - val_loss: 1.2920 - val_acc: 0.8481\n",
      "Epoch 94/500\n",
      "320/320 - 0s - loss: 4.2317e-05 - acc: 1.0000 - val_loss: 1.2931 - val_acc: 0.8481\n",
      "Epoch 95/500\n",
      "320/320 - 0s - loss: 4.1101e-05 - acc: 1.0000 - val_loss: 1.2964 - val_acc: 0.8481\n",
      "Epoch 96/500\n",
      "320/320 - 0s - loss: 4.0034e-05 - acc: 1.0000 - val_loss: 1.3005 - val_acc: 0.8481\n",
      "Epoch 97/500\n",
      "320/320 - 0s - loss: 3.8791e-05 - acc: 1.0000 - val_loss: 1.3065 - val_acc: 0.8481\n",
      "Epoch 98/500\n",
      "320/320 - 0s - loss: 3.7872e-05 - acc: 1.0000 - val_loss: 1.3127 - val_acc: 0.8481\n",
      "Epoch 99/500\n",
      "320/320 - 0s - loss: 3.6830e-05 - acc: 1.0000 - val_loss: 1.3167 - val_acc: 0.8481\n",
      "Epoch 100/500\n",
      "320/320 - 0s - loss: 3.5976e-05 - acc: 1.0000 - val_loss: 1.3182 - val_acc: 0.8481\n",
      "Epoch 101/500\n",
      "320/320 - 0s - loss: 3.4851e-05 - acc: 1.0000 - val_loss: 1.3222 - val_acc: 0.8481\n",
      "Epoch 102/500\n",
      "320/320 - 0s - loss: 3.3991e-05 - acc: 1.0000 - val_loss: 1.3257 - val_acc: 0.8481\n",
      "Epoch 103/500\n",
      "320/320 - 0s - loss: 3.3155e-05 - acc: 1.0000 - val_loss: 1.3298 - val_acc: 0.8481\n",
      "Epoch 104/500\n",
      "320/320 - 0s - loss: 3.2269e-05 - acc: 1.0000 - val_loss: 1.3339 - val_acc: 0.8481\n",
      "Epoch 105/500\n",
      "320/320 - 0s - loss: 3.1442e-05 - acc: 1.0000 - val_loss: 1.3402 - val_acc: 0.8481\n",
      "Epoch 106/500\n",
      "320/320 - 0s - loss: 3.0821e-05 - acc: 1.0000 - val_loss: 1.3426 - val_acc: 0.8481\n",
      "Epoch 107/500\n",
      "320/320 - 0s - loss: 2.9980e-05 - acc: 1.0000 - val_loss: 1.3472 - val_acc: 0.8481\n",
      "Epoch 108/500\n",
      "320/320 - 0s - loss: 2.9246e-05 - acc: 1.0000 - val_loss: 1.3508 - val_acc: 0.8481\n",
      "Epoch 109/500\n",
      "320/320 - 0s - loss: 2.8630e-05 - acc: 1.0000 - val_loss: 1.3538 - val_acc: 0.8481\n",
      "Epoch 110/500\n",
      "320/320 - 0s - loss: 2.7880e-05 - acc: 1.0000 - val_loss: 1.3577 - val_acc: 0.8481\n",
      "Epoch 111/500\n",
      "320/320 - 0s - loss: 2.7270e-05 - acc: 1.0000 - val_loss: 1.3616 - val_acc: 0.8481\n",
      "Epoch 112/500\n",
      "320/320 - 0s - loss: 2.6621e-05 - acc: 1.0000 - val_loss: 1.3649 - val_acc: 0.8481\n",
      "Epoch 113/500\n",
      "320/320 - 0s - loss: 2.6049e-05 - acc: 1.0000 - val_loss: 1.3675 - val_acc: 0.8481\n",
      "Epoch 114/500\n",
      "320/320 - 0s - loss: 2.5420e-05 - acc: 1.0000 - val_loss: 1.3724 - val_acc: 0.8481\n",
      "Epoch 115/500\n",
      "320/320 - 0s - loss: 2.4915e-05 - acc: 1.0000 - val_loss: 1.3771 - val_acc: 0.8481\n",
      "Epoch 116/500\n",
      "320/320 - 0s - loss: 2.4324e-05 - acc: 1.0000 - val_loss: 1.3797 - val_acc: 0.8481\n",
      "Epoch 117/500\n",
      "320/320 - 0s - loss: 2.3791e-05 - acc: 1.0000 - val_loss: 1.3820 - val_acc: 0.8481\n",
      "Epoch 118/500\n",
      "320/320 - 0s - loss: 2.3320e-05 - acc: 1.0000 - val_loss: 1.3870 - val_acc: 0.8481\n",
      "Epoch 119/500\n",
      "320/320 - 0s - loss: 2.2827e-05 - acc: 1.0000 - val_loss: 1.3897 - val_acc: 0.8481\n",
      "Epoch 120/500\n",
      "320/320 - 0s - loss: 2.2271e-05 - acc: 1.0000 - val_loss: 1.3937 - val_acc: 0.8481\n",
      "Epoch 121/500\n",
      "320/320 - 0s - loss: 2.1868e-05 - acc: 1.0000 - val_loss: 1.3967 - val_acc: 0.8481\n",
      "Epoch 122/500\n",
      "320/320 - 0s - loss: 2.1368e-05 - acc: 1.0000 - val_loss: 1.3986 - val_acc: 0.8481\n",
      "Epoch 123/500\n",
      "320/320 - 0s - loss: 2.0956e-05 - acc: 1.0000 - val_loss: 1.4021 - val_acc: 0.8481\n",
      "Epoch 124/500\n",
      "320/320 - 0s - loss: 2.0526e-05 - acc: 1.0000 - val_loss: 1.4060 - val_acc: 0.8481\n",
      "Epoch 125/500\n",
      "320/320 - 0s - loss: 2.0060e-05 - acc: 1.0000 - val_loss: 1.4114 - val_acc: 0.8481\n",
      "Epoch 126/500\n",
      "320/320 - 0s - loss: 1.9728e-05 - acc: 1.0000 - val_loss: 1.4163 - val_acc: 0.8481\n",
      "Epoch 127/500\n",
      "320/320 - 0s - loss: 1.9284e-05 - acc: 1.0000 - val_loss: 1.4190 - val_acc: 0.8481\n",
      "Epoch 128/500\n",
      "320/320 - 0s - loss: 1.8935e-05 - acc: 1.0000 - val_loss: 1.4190 - val_acc: 0.8481\n",
      "Epoch 129/500\n",
      "320/320 - 0s - loss: 1.8561e-05 - acc: 1.0000 - val_loss: 1.4207 - val_acc: 0.8481\n",
      "Epoch 130/500\n",
      "320/320 - 0s - loss: 1.8169e-05 - acc: 1.0000 - val_loss: 1.4253 - val_acc: 0.8481\n",
      "Epoch 131/500\n",
      "320/320 - 0s - loss: 1.7824e-05 - acc: 1.0000 - val_loss: 1.4296 - val_acc: 0.8481\n",
      "Epoch 132/500\n",
      "320/320 - 0s - loss: 1.7519e-05 - acc: 1.0000 - val_loss: 1.4306 - val_acc: 0.8481\n",
      "Epoch 133/500\n",
      "320/320 - 0s - loss: 1.7137e-05 - acc: 1.0000 - val_loss: 1.4337 - val_acc: 0.8481\n",
      "Epoch 134/500\n",
      "320/320 - 0s - loss: 1.6859e-05 - acc: 1.0000 - val_loss: 1.4386 - val_acc: 0.8481\n",
      "Epoch 135/500\n",
      "320/320 - 0s - loss: 1.6532e-05 - acc: 1.0000 - val_loss: 1.4410 - val_acc: 0.8481\n",
      "Epoch 136/500\n",
      "320/320 - 0s - loss: 1.6208e-05 - acc: 1.0000 - val_loss: 1.4437 - val_acc: 0.8481\n",
      "Epoch 137/500\n",
      "320/320 - 0s - loss: 1.5938e-05 - acc: 1.0000 - val_loss: 1.4457 - val_acc: 0.8481\n",
      "Epoch 138/500\n",
      "320/320 - 0s - loss: 1.5633e-05 - acc: 1.0000 - val_loss: 1.4504 - val_acc: 0.8481\n",
      "Epoch 139/500\n",
      "320/320 - 0s - loss: 1.5350e-05 - acc: 1.0000 - val_loss: 1.4537 - val_acc: 0.8481\n",
      "Epoch 140/500\n",
      "320/320 - 0s - loss: 1.5074e-05 - acc: 1.0000 - val_loss: 1.4552 - val_acc: 0.8481\n",
      "Epoch 141/500\n",
      "320/320 - 0s - loss: 1.4884e-05 - acc: 1.0000 - val_loss: 1.4605 - val_acc: 0.8481\n",
      "Epoch 142/500\n",
      "320/320 - 0s - loss: 1.4536e-05 - acc: 1.0000 - val_loss: 1.4617 - val_acc: 0.8481\n",
      "Epoch 143/500\n",
      "320/320 - 0s - loss: 1.4346e-05 - acc: 1.0000 - val_loss: 1.4630 - val_acc: 0.8481\n",
      "Epoch 144/500\n",
      "320/320 - 0s - loss: 1.4060e-05 - acc: 1.0000 - val_loss: 1.4679 - val_acc: 0.8481\n",
      "Epoch 145/500\n",
      "320/320 - 0s - loss: 1.3833e-05 - acc: 1.0000 - val_loss: 1.4708 - val_acc: 0.8481\n",
      "Epoch 146/500\n",
      "320/320 - 0s - loss: 1.3582e-05 - acc: 1.0000 - val_loss: 1.4742 - val_acc: 0.8481\n",
      "Epoch 147/500\n",
      "320/320 - 0s - loss: 1.3340e-05 - acc: 1.0000 - val_loss: 1.4746 - val_acc: 0.8481\n",
      "Epoch 148/500\n",
      "320/320 - 0s - loss: 1.3186e-05 - acc: 1.0000 - val_loss: 1.4756 - val_acc: 0.8481\n",
      "Epoch 149/500\n",
      "320/320 - 0s - loss: 1.2893e-05 - acc: 1.0000 - val_loss: 1.4801 - val_acc: 0.8481\n",
      "Epoch 150/500\n",
      "320/320 - 0s - loss: 1.2684e-05 - acc: 1.0000 - val_loss: 1.4842 - val_acc: 0.8481\n",
      "Epoch 151/500\n",
      "320/320 - 0s - loss: 1.2480e-05 - acc: 1.0000 - val_loss: 1.4871 - val_acc: 0.8481\n",
      "Epoch 152/500\n",
      "320/320 - 0s - loss: 1.2316e-05 - acc: 1.0000 - val_loss: 1.4877 - val_acc: 0.8481\n",
      "Epoch 153/500\n",
      "320/320 - 0s - loss: 1.2064e-05 - acc: 1.0000 - val_loss: 1.4922 - val_acc: 0.8481\n",
      "Epoch 154/500\n",
      "320/320 - 0s - loss: 1.1881e-05 - acc: 1.0000 - val_loss: 1.4954 - val_acc: 0.8481\n",
      "Epoch 155/500\n",
      "320/320 - 0s - loss: 1.1680e-05 - acc: 1.0000 - val_loss: 1.4975 - val_acc: 0.8481\n",
      "Epoch 156/500\n",
      "320/320 - 0s - loss: 1.1516e-05 - acc: 1.0000 - val_loss: 1.4991 - val_acc: 0.8481\n",
      "Epoch 157/500\n",
      "320/320 - 0s - loss: 1.1336e-05 - acc: 1.0000 - val_loss: 1.5018 - val_acc: 0.8481\n",
      "Epoch 158/500\n",
      "320/320 - 0s - loss: 1.1169e-05 - acc: 1.0000 - val_loss: 1.5037 - val_acc: 0.8481\n",
      "Epoch 159/500\n",
      "320/320 - 0s - loss: 1.0988e-05 - acc: 1.0000 - val_loss: 1.5084 - val_acc: 0.8481\n",
      "Epoch 160/500\n",
      "320/320 - 0s - loss: 1.0814e-05 - acc: 1.0000 - val_loss: 1.5099 - val_acc: 0.8481\n",
      "Epoch 161/500\n",
      "320/320 - 0s - loss: 1.0692e-05 - acc: 1.0000 - val_loss: 1.5133 - val_acc: 0.8481\n",
      "Epoch 162/500\n",
      "320/320 - 0s - loss: 1.0469e-05 - acc: 1.0000 - val_loss: 1.5145 - val_acc: 0.8481\n",
      "Epoch 163/500\n",
      "320/320 - 0s - loss: 1.0330e-05 - acc: 1.0000 - val_loss: 1.5161 - val_acc: 0.8481\n",
      "Epoch 164/500\n",
      "320/320 - 0s - loss: 1.0173e-05 - acc: 1.0000 - val_loss: 1.5186 - val_acc: 0.8481\n",
      "Epoch 165/500\n",
      "320/320 - 0s - loss: 1.0012e-05 - acc: 1.0000 - val_loss: 1.5217 - val_acc: 0.8481\n",
      "Epoch 166/500\n",
      "320/320 - 0s - loss: 9.8812e-06 - acc: 1.0000 - val_loss: 1.5244 - val_acc: 0.8481\n",
      "Epoch 167/500\n",
      "320/320 - 0s - loss: 9.7404e-06 - acc: 1.0000 - val_loss: 1.5257 - val_acc: 0.8481\n",
      "Epoch 168/500\n",
      "320/320 - 0s - loss: 9.5810e-06 - acc: 1.0000 - val_loss: 1.5297 - val_acc: 0.8481\n",
      "Epoch 169/500\n",
      "320/320 - 0s - loss: 9.4517e-06 - acc: 1.0000 - val_loss: 1.5311 - val_acc: 0.8481\n",
      "Epoch 170/500\n",
      "320/320 - 0s - loss: 9.3213e-06 - acc: 1.0000 - val_loss: 1.5330 - val_acc: 0.8481\n",
      "Epoch 171/500\n",
      "320/320 - 0s - loss: 9.1861e-06 - acc: 1.0000 - val_loss: 1.5376 - val_acc: 0.8481\n",
      "Epoch 172/500\n",
      "320/320 - 0s - loss: 9.0401e-06 - acc: 1.0000 - val_loss: 1.5399 - val_acc: 0.8481\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 173/500\n",
      "320/320 - 0s - loss: 8.9142e-06 - acc: 1.0000 - val_loss: 1.5406 - val_acc: 0.8481\n",
      "Epoch 174/500\n",
      "320/320 - 0s - loss: 8.7857e-06 - acc: 1.0000 - val_loss: 1.5435 - val_acc: 0.8481\n",
      "Epoch 175/500\n",
      "320/320 - 0s - loss: 8.6687e-06 - acc: 1.0000 - val_loss: 1.5456 - val_acc: 0.8481\n",
      "Epoch 176/500\n",
      "320/320 - 0s - loss: 8.5365e-06 - acc: 1.0000 - val_loss: 1.5480 - val_acc: 0.8481\n",
      "Epoch 177/500\n",
      "320/320 - 0s - loss: 8.4560e-06 - acc: 1.0000 - val_loss: 1.5513 - val_acc: 0.8481\n",
      "Epoch 178/500\n",
      "320/320 - 0s - loss: 8.3152e-06 - acc: 1.0000 - val_loss: 1.5513 - val_acc: 0.8481\n",
      "Epoch 179/500\n",
      "320/320 - 0s - loss: 8.1968e-06 - acc: 1.0000 - val_loss: 1.5528 - val_acc: 0.8481\n",
      "Epoch 180/500\n",
      "320/320 - 0s - loss: 8.1055e-06 - acc: 1.0000 - val_loss: 1.5576 - val_acc: 0.8481\n",
      "Epoch 181/500\n",
      "320/320 - 0s - loss: 7.9677e-06 - acc: 1.0000 - val_loss: 1.5597 - val_acc: 0.8481\n",
      "Epoch 182/500\n",
      "320/320 - 0s - loss: 7.8604e-06 - acc: 1.0000 - val_loss: 1.5615 - val_acc: 0.8481\n",
      "Epoch 183/500\n",
      "320/320 - 0s - loss: 7.7673e-06 - acc: 1.0000 - val_loss: 1.5625 - val_acc: 0.8481\n",
      "Epoch 184/500\n",
      "320/320 - 0s - loss: 7.6533e-06 - acc: 1.0000 - val_loss: 1.5653 - val_acc: 0.8481\n",
      "Epoch 185/500\n",
      "320/320 - 0s - loss: 7.5483e-06 - acc: 1.0000 - val_loss: 1.5670 - val_acc: 0.8481\n",
      "Epoch 186/500\n",
      "320/320 - 0s - loss: 7.4581e-06 - acc: 1.0000 - val_loss: 1.5699 - val_acc: 0.8481\n",
      "Epoch 187/500\n",
      "320/320 - 0s - loss: 7.3601e-06 - acc: 1.0000 - val_loss: 1.5721 - val_acc: 0.8481\n",
      "Epoch 188/500\n",
      "320/320 - 0s - loss: 7.2547e-06 - acc: 1.0000 - val_loss: 1.5741 - val_acc: 0.8481\n",
      "Epoch 189/500\n",
      "320/320 - 0s - loss: 7.1582e-06 - acc: 1.0000 - val_loss: 1.5764 - val_acc: 0.8481\n",
      "Epoch 190/500\n",
      "320/320 - 0s - loss: 7.0629e-06 - acc: 1.0000 - val_loss: 1.5786 - val_acc: 0.8481\n",
      "Epoch 191/500\n",
      "320/320 - 0s - loss: 6.9750e-06 - acc: 1.0000 - val_loss: 1.5806 - val_acc: 0.8481\n",
      "Epoch 192/500\n",
      "320/320 - 0s - loss: 6.8956e-06 - acc: 1.0000 - val_loss: 1.5825 - val_acc: 0.8481\n",
      "Epoch 193/500\n",
      "320/320 - 0s - loss: 6.8245e-06 - acc: 1.0000 - val_loss: 1.5828 - val_acc: 0.8481\n",
      "Epoch 194/500\n",
      "320/320 - 0s - loss: 6.7109e-06 - acc: 1.0000 - val_loss: 1.5871 - val_acc: 0.8481\n",
      "Epoch 195/500\n",
      "320/320 - 0s - loss: 6.6274e-06 - acc: 1.0000 - val_loss: 1.5893 - val_acc: 0.8481\n",
      "Epoch 196/500\n",
      "320/320 - 0s - loss: 6.5365e-06 - acc: 1.0000 - val_loss: 1.5915 - val_acc: 0.8481\n",
      "Epoch 197/500\n",
      "320/320 - 0s - loss: 6.4695e-06 - acc: 1.0000 - val_loss: 1.5920 - val_acc: 0.8481\n",
      "Epoch 198/500\n",
      "320/320 - 0s - loss: 6.3991e-06 - acc: 1.0000 - val_loss: 1.5961 - val_acc: 0.8481\n",
      "Epoch 199/500\n",
      "320/320 - 0s - loss: 6.3134e-06 - acc: 1.0000 - val_loss: 1.5962 - val_acc: 0.8481\n",
      "Epoch 200/500\n",
      "320/320 - 0s - loss: 6.2214e-06 - acc: 1.0000 - val_loss: 1.5991 - val_acc: 0.8481\n",
      "Epoch 201/500\n",
      "320/320 - 0s - loss: 6.1622e-06 - acc: 1.0000 - val_loss: 1.6015 - val_acc: 0.8481\n",
      "Epoch 202/500\n",
      "320/320 - 0s - loss: 6.0690e-06 - acc: 1.0000 - val_loss: 1.6035 - val_acc: 0.8481\n",
      "Epoch 203/500\n",
      "320/320 - 0s - loss: 5.9875e-06 - acc: 1.0000 - val_loss: 1.6052 - val_acc: 0.8481\n",
      "Epoch 204/500\n",
      "320/320 - 0s - loss: 5.9227e-06 - acc: 1.0000 - val_loss: 1.6071 - val_acc: 0.8481\n",
      "Epoch 205/500\n",
      "320/320 - 0s - loss: 5.8608e-06 - acc: 1.0000 - val_loss: 1.6104 - val_acc: 0.8481\n",
      "Epoch 206/500\n",
      "320/320 - 0s - loss: 5.7815e-06 - acc: 1.0000 - val_loss: 1.6118 - val_acc: 0.8481\n",
      "Epoch 207/500\n",
      "320/320 - 0s - loss: 5.7215e-06 - acc: 1.0000 - val_loss: 1.6135 - val_acc: 0.8481\n",
      "Epoch 208/500\n",
      "320/320 - 0s - loss: 5.6451e-06 - acc: 1.0000 - val_loss: 1.6145 - val_acc: 0.8481\n",
      "Epoch 209/500\n",
      "320/320 - 0s - loss: 5.5934e-06 - acc: 1.0000 - val_loss: 1.6176 - val_acc: 0.8481\n",
      "Epoch 210/500\n",
      "320/320 - 0s - loss: 5.5025e-06 - acc: 1.0000 - val_loss: 1.6196 - val_acc: 0.8481\n",
      "Epoch 211/500\n",
      "320/320 - 0s - loss: 5.4496e-06 - acc: 1.0000 - val_loss: 1.6211 - val_acc: 0.8481\n",
      "Epoch 212/500\n",
      "320/320 - 0s - loss: 5.3728e-06 - acc: 1.0000 - val_loss: 1.6228 - val_acc: 0.8481\n",
      "Epoch 213/500\n",
      "320/320 - 0s - loss: 5.3166e-06 - acc: 1.0000 - val_loss: 1.6248 - val_acc: 0.8481\n",
      "Epoch 214/500\n",
      "320/320 - 0s - loss: 5.2596e-06 - acc: 1.0000 - val_loss: 1.6272 - val_acc: 0.8481\n",
      "Epoch 215/500\n",
      "320/320 - 0s - loss: 5.1892e-06 - acc: 1.0000 - val_loss: 1.6282 - val_acc: 0.8481\n",
      "Epoch 216/500\n",
      "320/320 - 0s - loss: 5.1400e-06 - acc: 1.0000 - val_loss: 1.6310 - val_acc: 0.8481\n",
      "Epoch 217/500\n",
      "320/320 - 0s - loss: 5.0804e-06 - acc: 1.0000 - val_loss: 1.6329 - val_acc: 0.8481\n",
      "Epoch 218/500\n",
      "320/320 - 0s - loss: 5.0234e-06 - acc: 1.0000 - val_loss: 1.6346 - val_acc: 0.8481\n",
      "Epoch 219/500\n",
      "320/320 - 0s - loss: 4.9657e-06 - acc: 1.0000 - val_loss: 1.6348 - val_acc: 0.8481\n",
      "Epoch 220/500\n",
      "320/320 - 0s - loss: 4.9076e-06 - acc: 1.0000 - val_loss: 1.6375 - val_acc: 0.8481\n",
      "Epoch 221/500\n",
      "320/320 - 0s - loss: 4.8517e-06 - acc: 1.0000 - val_loss: 1.6397 - val_acc: 0.8481\n",
      "Epoch 222/500\n",
      "320/320 - 0s - loss: 4.7962e-06 - acc: 1.0000 - val_loss: 1.6411 - val_acc: 0.8481\n",
      "Epoch 223/500\n",
      "320/320 - 0s - loss: 4.7377e-06 - acc: 1.0000 - val_loss: 1.6439 - val_acc: 0.8481\n",
      "Epoch 224/500\n",
      "320/320 - 0s - loss: 4.6952e-06 - acc: 1.0000 - val_loss: 1.6460 - val_acc: 0.8481\n",
      "Epoch 225/500\n",
      "320/320 - 0s - loss: 4.6677e-06 - acc: 1.0000 - val_loss: 1.6455 - val_acc: 0.8481\n",
      "Epoch 226/500\n",
      "320/320 - 0s - loss: 4.5831e-06 - acc: 1.0000 - val_loss: 1.6480 - val_acc: 0.8481\n",
      "Epoch 227/500\n",
      "320/320 - 0s - loss: 4.5410e-06 - acc: 1.0000 - val_loss: 1.6520 - val_acc: 0.8481\n",
      "Epoch 228/500\n",
      "320/320 - 0s - loss: 4.4769e-06 - acc: 1.0000 - val_loss: 1.6533 - val_acc: 0.8481\n",
      "Epoch 229/500\n",
      "320/320 - 0s - loss: 4.4270e-06 - acc: 1.0000 - val_loss: 1.6542 - val_acc: 0.8481\n",
      "Epoch 230/500\n",
      "320/320 - 0s - loss: 4.3857e-06 - acc: 1.0000 - val_loss: 1.6565 - val_acc: 0.8481\n",
      "Epoch 231/500\n",
      "320/320 - 0s - loss: 4.3380e-06 - acc: 1.0000 - val_loss: 1.6587 - val_acc: 0.8481\n",
      "Epoch 232/500\n",
      "320/320 - 0s - loss: 4.2903e-06 - acc: 1.0000 - val_loss: 1.6599 - val_acc: 0.8481\n",
      "Epoch 233/500\n",
      "320/320 - 0s - loss: 4.2356e-06 - acc: 1.0000 - val_loss: 1.6621 - val_acc: 0.8481\n",
      "Epoch 234/500\n",
      "320/320 - 0s - loss: 4.1916e-06 - acc: 1.0000 - val_loss: 1.6639 - val_acc: 0.8481\n",
      "Epoch 235/500\n",
      "320/320 - 0s - loss: 4.1469e-06 - acc: 1.0000 - val_loss: 1.6659 - val_acc: 0.8481\n",
      "Epoch 236/500\n",
      "320/320 - 0s - loss: 4.1085e-06 - acc: 1.0000 - val_loss: 1.6670 - val_acc: 0.8481\n",
      "Epoch 237/500\n",
      "320/320 - 0s - loss: 4.0597e-06 - acc: 1.0000 - val_loss: 1.6689 - val_acc: 0.8481\n",
      "Epoch 238/500\n",
      "320/320 - 0s - loss: 4.0251e-06 - acc: 1.0000 - val_loss: 1.6700 - val_acc: 0.8481\n",
      "Epoch 239/500\n",
      "320/320 - 0s - loss: 3.9763e-06 - acc: 1.0000 - val_loss: 1.6733 - val_acc: 0.8481\n",
      "Epoch 240/500\n",
      "320/320 - 0s - loss: 3.9282e-06 - acc: 1.0000 - val_loss: 1.6751 - val_acc: 0.8481\n",
      "Epoch 241/500\n",
      "320/320 - 0s - loss: 3.8951e-06 - acc: 1.0000 - val_loss: 1.6767 - val_acc: 0.8481\n",
      "Epoch 242/500\n",
      "320/320 - 0s - loss: 3.8504e-06 - acc: 1.0000 - val_loss: 1.6769 - val_acc: 0.8481\n",
      "Epoch 243/500\n",
      "320/320 - 0s - loss: 3.8236e-06 - acc: 1.0000 - val_loss: 1.6800 - val_acc: 0.8481\n",
      "Epoch 244/500\n",
      "320/320 - 0s - loss: 3.7654e-06 - acc: 1.0000 - val_loss: 1.6810 - val_acc: 0.8481\n",
      "Epoch 245/500\n",
      "320/320 - 0s - loss: 3.7356e-06 - acc: 1.0000 - val_loss: 1.6821 - val_acc: 0.8481\n",
      "Epoch 246/500\n",
      "320/320 - 0s - loss: 3.6939e-06 - acc: 1.0000 - val_loss: 1.6839 - val_acc: 0.8481\n",
      "Epoch 247/500\n",
      "320/320 - 0s - loss: 3.6496e-06 - acc: 1.0000 - val_loss: 1.6859 - val_acc: 0.8481\n",
      "Epoch 248/500\n",
      "320/320 - 0s - loss: 3.6168e-06 - acc: 1.0000 - val_loss: 1.6880 - val_acc: 0.8481\n",
      "Epoch 249/500\n",
      "320/320 - 0s - loss: 3.5766e-06 - acc: 1.0000 - val_loss: 1.6897 - val_acc: 0.8481\n",
      "Epoch 250/500\n",
      "320/320 - 0s - loss: 3.5386e-06 - acc: 1.0000 - val_loss: 1.6918 - val_acc: 0.8481\n",
      "Epoch 251/500\n",
      "320/320 - 0s - loss: 3.5065e-06 - acc: 1.0000 - val_loss: 1.6939 - val_acc: 0.8481\n",
      "Epoch 252/500\n",
      "320/320 - 0s - loss: 3.4846e-06 - acc: 1.0000 - val_loss: 1.6937 - val_acc: 0.8481\n",
      "Epoch 253/500\n",
      "320/320 - 0s - loss: 3.4347e-06 - acc: 1.0000 - val_loss: 1.6961 - val_acc: 0.8481\n",
      "Epoch 254/500\n",
      "320/320 - 0s - loss: 3.4004e-06 - acc: 1.0000 - val_loss: 1.6985 - val_acc: 0.8481\n",
      "Epoch 255/500\n",
      "320/320 - 0s - loss: 3.3628e-06 - acc: 1.0000 - val_loss: 1.7006 - val_acc: 0.8481\n",
      "Epoch 256/500\n",
      "320/320 - 0s - loss: 3.3363e-06 - acc: 1.0000 - val_loss: 1.7027 - val_acc: 0.8418\n",
      "Epoch 257/500\n",
      "320/320 - 0s - loss: 3.3054e-06 - acc: 1.0000 - val_loss: 1.7026 - val_acc: 0.8481\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 258/500\n",
      "320/320 - 0s - loss: 3.2625e-06 - acc: 1.0000 - val_loss: 1.7049 - val_acc: 0.8481\n",
      "Epoch 259/500\n",
      "320/320 - 0s - loss: 3.2305e-06 - acc: 1.0000 - val_loss: 1.7062 - val_acc: 0.8481\n",
      "Epoch 260/500\n",
      "320/320 - 0s - loss: 3.1992e-06 - acc: 1.0000 - val_loss: 1.7086 - val_acc: 0.8481\n",
      "Epoch 261/500\n",
      "320/320 - 0s - loss: 3.1664e-06 - acc: 1.0000 - val_loss: 1.7096 - val_acc: 0.8481\n",
      "Epoch 262/500\n",
      "320/320 - 0s - loss: 3.1344e-06 - acc: 1.0000 - val_loss: 1.7114 - val_acc: 0.8481\n",
      "Epoch 263/500\n",
      "320/320 - 0s - loss: 3.1027e-06 - acc: 1.0000 - val_loss: 1.7137 - val_acc: 0.8481\n",
      "Epoch 264/500\n",
      "320/320 - 0s - loss: 3.0714e-06 - acc: 1.0000 - val_loss: 1.7150 - val_acc: 0.8481\n",
      "Epoch 265/500\n",
      "320/320 - 0s - loss: 3.0413e-06 - acc: 1.0000 - val_loss: 1.7165 - val_acc: 0.8481\n",
      "Epoch 266/500\n",
      "320/320 - 0s - loss: 3.0133e-06 - acc: 1.0000 - val_loss: 1.7180 - val_acc: 0.8481\n",
      "Epoch 267/500\n",
      "320/320 - 0s - loss: 2.9839e-06 - acc: 1.0000 - val_loss: 1.7197 - val_acc: 0.8481\n",
      "Epoch 268/500\n",
      "320/320 - 0s - loss: 2.9549e-06 - acc: 1.0000 - val_loss: 1.7219 - val_acc: 0.8481\n",
      "Epoch 269/500\n",
      "320/320 - 0s - loss: 2.9247e-06 - acc: 1.0000 - val_loss: 1.7227 - val_acc: 0.8481\n",
      "Epoch 270/500\n",
      "320/320 - 0s - loss: 2.8990e-06 - acc: 1.0000 - val_loss: 1.7255 - val_acc: 0.8418\n",
      "Epoch 271/500\n",
      "320/320 - 0s - loss: 2.8722e-06 - acc: 1.0000 - val_loss: 1.7269 - val_acc: 0.8481\n",
      "Epoch 272/500\n",
      "320/320 - 0s - loss: 2.8427e-06 - acc: 1.0000 - val_loss: 1.7281 - val_acc: 0.8481\n",
      "Epoch 273/500\n",
      "320/320 - 0s - loss: 2.8166e-06 - acc: 1.0000 - val_loss: 1.7303 - val_acc: 0.8418\n",
      "Epoch 274/500\n",
      "320/320 - 0s - loss: 2.7839e-06 - acc: 1.0000 - val_loss: 1.7304 - val_acc: 0.8481\n",
      "Epoch 275/500\n",
      "320/320 - 0s - loss: 2.7604e-06 - acc: 1.0000 - val_loss: 1.7329 - val_acc: 0.8481\n",
      "Epoch 276/500\n",
      "320/320 - 0s - loss: 2.7377e-06 - acc: 1.0000 - val_loss: 1.7353 - val_acc: 0.8418\n",
      "Epoch 277/500\n",
      "320/320 - 0s - loss: 2.7045e-06 - acc: 1.0000 - val_loss: 1.7365 - val_acc: 0.8481\n",
      "Epoch 278/500\n",
      "320/320 - 0s - loss: 2.6829e-06 - acc: 1.0000 - val_loss: 1.7374 - val_acc: 0.8481\n",
      "Epoch 279/500\n",
      "320/320 - 0s - loss: 2.6561e-06 - acc: 1.0000 - val_loss: 1.7392 - val_acc: 0.8481\n",
      "Epoch 280/500\n",
      "320/320 - 0s - loss: 2.6296e-06 - acc: 1.0000 - val_loss: 1.7412 - val_acc: 0.8481\n",
      "Epoch 281/500\n",
      "320/320 - 0s - loss: 2.6080e-06 - acc: 1.0000 - val_loss: 1.7425 - val_acc: 0.8481\n",
      "Epoch 282/500\n",
      "320/320 - 0s - loss: 2.5887e-06 - acc: 1.0000 - val_loss: 1.7439 - val_acc: 0.8481\n",
      "Epoch 283/500\n",
      "320/320 - 0s - loss: 2.5581e-06 - acc: 1.0000 - val_loss: 1.7460 - val_acc: 0.8481\n",
      "Epoch 284/500\n",
      "320/320 - 0s - loss: 2.5350e-06 - acc: 1.0000 - val_loss: 1.7469 - val_acc: 0.8481\n",
      "Epoch 285/500\n",
      "320/320 - 0s - loss: 2.5108e-06 - acc: 1.0000 - val_loss: 1.7485 - val_acc: 0.8481\n",
      "Epoch 286/500\n",
      "320/320 - 0s - loss: 2.4892e-06 - acc: 1.0000 - val_loss: 1.7511 - val_acc: 0.8418\n",
      "Epoch 287/500\n",
      "320/320 - 0s - loss: 2.4650e-06 - acc: 1.0000 - val_loss: 1.7523 - val_acc: 0.8481\n",
      "Epoch 288/500\n",
      "320/320 - 0s - loss: 2.4456e-06 - acc: 1.0000 - val_loss: 1.7533 - val_acc: 0.8481\n",
      "Epoch 289/500\n",
      "320/320 - 0s - loss: 2.4210e-06 - acc: 1.0000 - val_loss: 1.7547 - val_acc: 0.8481\n",
      "Epoch 290/500\n",
      "320/320 - 0s - loss: 2.3979e-06 - acc: 1.0000 - val_loss: 1.7569 - val_acc: 0.8481\n",
      "Epoch 291/500\n",
      "320/320 - 0s - loss: 2.3797e-06 - acc: 1.0000 - val_loss: 1.7584 - val_acc: 0.8481\n",
      "Epoch 292/500\n",
      "320/320 - 0s - loss: 2.3525e-06 - acc: 1.0000 - val_loss: 1.7606 - val_acc: 0.8418\n",
      "Epoch 293/500\n",
      "320/320 - 0s - loss: 2.3331e-06 - acc: 1.0000 - val_loss: 1.7619 - val_acc: 0.8481\n",
      "Epoch 294/500\n",
      "320/320 - 0s - loss: 2.3111e-06 - acc: 1.0000 - val_loss: 1.7637 - val_acc: 0.8418\n",
      "Epoch 295/500\n",
      "320/320 - 0s - loss: 2.2918e-06 - acc: 1.0000 - val_loss: 1.7657 - val_acc: 0.8418\n",
      "Epoch 296/500\n",
      "320/320 - 0s - loss: 2.2713e-06 - acc: 1.0000 - val_loss: 1.7668 - val_acc: 0.8418\n",
      "Epoch 297/500\n",
      "320/320 - 0s - loss: 2.2474e-06 - acc: 1.0000 - val_loss: 1.7679 - val_acc: 0.8481\n",
      "Epoch 298/500\n",
      "320/320 - 0s - loss: 2.2299e-06 - acc: 1.0000 - val_loss: 1.7687 - val_acc: 0.8481\n",
      "Epoch 299/500\n",
      "320/320 - 0s - loss: 2.2087e-06 - acc: 1.0000 - val_loss: 1.7703 - val_acc: 0.8481\n",
      "Epoch 300/500\n",
      "320/320 - 0s - loss: 2.1871e-06 - acc: 1.0000 - val_loss: 1.7724 - val_acc: 0.8481\n",
      "Epoch 301/500\n",
      "320/320 - 0s - loss: 2.1700e-06 - acc: 1.0000 - val_loss: 1.7738 - val_acc: 0.8481\n",
      "Epoch 302/500\n",
      "320/320 - 0s - loss: 2.1547e-06 - acc: 1.0000 - val_loss: 1.7761 - val_acc: 0.8418\n",
      "Epoch 303/500\n",
      "320/320 - 0s - loss: 2.1334e-06 - acc: 1.0000 - val_loss: 1.7768 - val_acc: 0.8481\n",
      "Epoch 304/500\n",
      "320/320 - 0s - loss: 2.1148e-06 - acc: 1.0000 - val_loss: 1.7781 - val_acc: 0.8481\n",
      "Epoch 305/500\n",
      "320/320 - 0s - loss: 2.0940e-06 - acc: 1.0000 - val_loss: 1.7796 - val_acc: 0.8481\n",
      "Epoch 306/500\n",
      "320/320 - 0s - loss: 2.0776e-06 - acc: 1.0000 - val_loss: 1.7812 - val_acc: 0.8481\n",
      "Epoch 307/500\n",
      "320/320 - 0s - loss: 2.0604e-06 - acc: 1.0000 - val_loss: 1.7823 - val_acc: 0.8481\n",
      "Epoch 308/500\n",
      "320/320 - 0s - loss: 2.0392e-06 - acc: 1.0000 - val_loss: 1.7846 - val_acc: 0.8481\n",
      "Epoch 309/500\n",
      "320/320 - 0s - loss: 2.0206e-06 - acc: 1.0000 - val_loss: 1.7862 - val_acc: 0.8481\n",
      "Epoch 310/500\n",
      "320/320 - 0s - loss: 2.0031e-06 - acc: 1.0000 - val_loss: 1.7885 - val_acc: 0.8418\n",
      "Epoch 311/500\n",
      "320/320 - 0s - loss: 1.9941e-06 - acc: 1.0000 - val_loss: 1.7885 - val_acc: 0.8481\n",
      "Epoch 312/500\n",
      "320/320 - 0s - loss: 1.9673e-06 - acc: 1.0000 - val_loss: 1.7907 - val_acc: 0.8481\n",
      "Epoch 313/500\n",
      "320/320 - 0s - loss: 1.9520e-06 - acc: 1.0000 - val_loss: 1.7922 - val_acc: 0.8481\n",
      "Epoch 314/500\n",
      "320/320 - 0s - loss: 1.9353e-06 - acc: 1.0000 - val_loss: 1.7938 - val_acc: 0.8418\n",
      "Epoch 315/500\n",
      "320/320 - 0s - loss: 1.9166e-06 - acc: 1.0000 - val_loss: 1.7951 - val_acc: 0.8481\n",
      "Epoch 316/500\n",
      "320/320 - 0s - loss: 1.9002e-06 - acc: 1.0000 - val_loss: 1.7966 - val_acc: 0.8481\n",
      "Epoch 317/500\n",
      "320/320 - 0s - loss: 1.8898e-06 - acc: 1.0000 - val_loss: 1.7971 - val_acc: 0.8481\n",
      "Epoch 318/500\n",
      "320/320 - 0s - loss: 1.8678e-06 - acc: 1.0000 - val_loss: 1.7997 - val_acc: 0.8418\n",
      "Epoch 319/500\n",
      "320/320 - 0s - loss: 1.8518e-06 - acc: 1.0000 - val_loss: 1.8009 - val_acc: 0.8481\n",
      "Epoch 320/500\n",
      "320/320 - 0s - loss: 1.8406e-06 - acc: 1.0000 - val_loss: 1.8022 - val_acc: 0.8481\n",
      "Epoch 321/500\n",
      "320/320 - 0s - loss: 1.8228e-06 - acc: 1.0000 - val_loss: 1.8036 - val_acc: 0.8481\n",
      "Epoch 322/500\n",
      "320/320 - 0s - loss: 1.8060e-06 - acc: 1.0000 - val_loss: 1.8052 - val_acc: 0.8481\n",
      "Epoch 323/500\n",
      "320/320 - 0s - loss: 1.7907e-06 - acc: 1.0000 - val_loss: 1.8065 - val_acc: 0.8481\n",
      "Epoch 324/500\n",
      "320/320 - 0s - loss: 1.7762e-06 - acc: 1.0000 - val_loss: 1.8089 - val_acc: 0.8418\n",
      "Epoch 325/500\n",
      "320/320 - 0s - loss: 1.7598e-06 - acc: 1.0000 - val_loss: 1.8093 - val_acc: 0.8481\n",
      "Epoch 326/500\n",
      "320/320 - 0s - loss: 1.7464e-06 - acc: 1.0000 - val_loss: 1.8116 - val_acc: 0.8418\n",
      "Epoch 327/500\n",
      "320/320 - 0s - loss: 1.7304e-06 - acc: 1.0000 - val_loss: 1.8121 - val_acc: 0.8481\n",
      "Epoch 328/500\n",
      "320/320 - 0s - loss: 1.7173e-06 - acc: 1.0000 - val_loss: 1.8129 - val_acc: 0.8481\n",
      "Epoch 329/500\n",
      "320/320 - 0s - loss: 1.6998e-06 - acc: 1.0000 - val_loss: 1.8150 - val_acc: 0.8481\n",
      "Epoch 330/500\n",
      "320/320 - 0s - loss: 1.6894e-06 - acc: 1.0000 - val_loss: 1.8172 - val_acc: 0.8418\n",
      "Epoch 331/500\n",
      "320/320 - 0s - loss: 1.6775e-06 - acc: 1.0000 - val_loss: 1.8177 - val_acc: 0.8481\n",
      "Epoch 332/500\n",
      "320/320 - 0s - loss: 1.6562e-06 - acc: 1.0000 - val_loss: 1.8193 - val_acc: 0.8481\n",
      "Epoch 333/500\n",
      "320/320 - 0s - loss: 1.6440e-06 - acc: 1.0000 - val_loss: 1.8201 - val_acc: 0.8481\n",
      "Epoch 334/500\n",
      "320/320 - 0s - loss: 1.6287e-06 - acc: 1.0000 - val_loss: 1.8226 - val_acc: 0.8481\n",
      "Epoch 335/500\n",
      "320/320 - 0s - loss: 1.6168e-06 - acc: 1.0000 - val_loss: 1.8245 - val_acc: 0.8418\n",
      "Epoch 336/500\n",
      "320/320 - 0s - loss: 1.6033e-06 - acc: 1.0000 - val_loss: 1.8258 - val_acc: 0.8418\n",
      "Epoch 337/500\n",
      "320/320 - 0s - loss: 1.5873e-06 - acc: 1.0000 - val_loss: 1.8267 - val_acc: 0.8418\n",
      "Epoch 338/500\n",
      "320/320 - 0s - loss: 1.5765e-06 - acc: 1.0000 - val_loss: 1.8280 - val_acc: 0.8481\n",
      "Epoch 339/500\n",
      "320/320 - 0s - loss: 1.5616e-06 - acc: 1.0000 - val_loss: 1.8296 - val_acc: 0.8481\n",
      "Epoch 340/500\n",
      "320/320 - 0s - loss: 1.5475e-06 - acc: 1.0000 - val_loss: 1.8311 - val_acc: 0.8481\n",
      "Epoch 341/500\n",
      "320/320 - 0s - loss: 1.5382e-06 - acc: 1.0000 - val_loss: 1.8328 - val_acc: 0.8418\n",
      "Epoch 342/500\n",
      "320/320 - 0s - loss: 1.5251e-06 - acc: 1.0000 - val_loss: 1.8341 - val_acc: 0.8418\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 343/500\n",
      "320/320 - 0s - loss: 1.5125e-06 - acc: 1.0000 - val_loss: 1.8347 - val_acc: 0.8481\n",
      "Epoch 344/500\n",
      "320/320 - 0s - loss: 1.4998e-06 - acc: 1.0000 - val_loss: 1.8368 - val_acc: 0.8418\n",
      "Epoch 345/500\n",
      "320/320 - 0s - loss: 1.4871e-06 - acc: 1.0000 - val_loss: 1.8378 - val_acc: 0.8481\n",
      "Epoch 346/500\n",
      "320/320 - 0s - loss: 1.4767e-06 - acc: 1.0000 - val_loss: 1.8396 - val_acc: 0.8418\n",
      "Epoch 347/500\n",
      "320/320 - 0s - loss: 1.4622e-06 - acc: 1.0000 - val_loss: 1.8407 - val_acc: 0.8481\n",
      "Epoch 348/500\n",
      "320/320 - 0s - loss: 1.4502e-06 - acc: 1.0000 - val_loss: 1.8425 - val_acc: 0.8418\n",
      "Epoch 349/500\n",
      "320/320 - 0s - loss: 1.4406e-06 - acc: 1.0000 - val_loss: 1.8431 - val_acc: 0.8481\n",
      "Epoch 350/500\n",
      "320/320 - 0s - loss: 1.4294e-06 - acc: 1.0000 - val_loss: 1.8444 - val_acc: 0.8481\n",
      "Epoch 351/500\n",
      "320/320 - 0s - loss: 1.4149e-06 - acc: 1.0000 - val_loss: 1.8458 - val_acc: 0.8481\n",
      "Epoch 352/500\n",
      "320/320 - 0s - loss: 1.4059e-06 - acc: 1.0000 - val_loss: 1.8477 - val_acc: 0.8418\n",
      "Epoch 353/500\n",
      "320/320 - 0s - loss: 1.3929e-06 - acc: 1.0000 - val_loss: 1.8493 - val_acc: 0.8418\n",
      "Epoch 354/500\n",
      "320/320 - 0s - loss: 1.3832e-06 - acc: 1.0000 - val_loss: 1.8507 - val_acc: 0.8418\n",
      "Epoch 355/500\n",
      "320/320 - 0s - loss: 1.3702e-06 - acc: 1.0000 - val_loss: 1.8515 - val_acc: 0.8481\n",
      "Epoch 356/500\n",
      "320/320 - 0s - loss: 1.3605e-06 - acc: 1.0000 - val_loss: 1.8532 - val_acc: 0.8481\n",
      "Epoch 357/500\n",
      "320/320 - 0s - loss: 1.3508e-06 - acc: 1.0000 - val_loss: 1.8541 - val_acc: 0.8544\n",
      "Epoch 358/500\n",
      "320/320 - 0s - loss: 1.3377e-06 - acc: 1.0000 - val_loss: 1.8563 - val_acc: 0.8418\n",
      "Epoch 359/500\n",
      "320/320 - 0s - loss: 1.3266e-06 - acc: 1.0000 - val_loss: 1.8580 - val_acc: 0.8418\n",
      "Epoch 360/500\n",
      "320/320 - 0s - loss: 1.3165e-06 - acc: 1.0000 - val_loss: 1.8588 - val_acc: 0.8481\n",
      "Epoch 361/500\n",
      "320/320 - 0s - loss: 1.3050e-06 - acc: 1.0000 - val_loss: 1.8599 - val_acc: 0.8544\n",
      "Epoch 362/500\n",
      "320/320 - 0s - loss: 1.2964e-06 - acc: 1.0000 - val_loss: 1.8613 - val_acc: 0.8544\n",
      "Epoch 363/500\n",
      "320/320 - 0s - loss: 1.2867e-06 - acc: 1.0000 - val_loss: 1.8626 - val_acc: 0.8544\n",
      "Epoch 364/500\n",
      "320/320 - 0s - loss: 1.2759e-06 - acc: 1.0000 - val_loss: 1.8646 - val_acc: 0.8481\n",
      "Epoch 365/500\n",
      "320/320 - 0s - loss: 1.2666e-06 - acc: 1.0000 - val_loss: 1.8650 - val_acc: 0.8544\n",
      "Epoch 366/500\n",
      "320/320 - 0s - loss: 1.2580e-06 - acc: 1.0000 - val_loss: 1.8667 - val_acc: 0.8481\n",
      "Epoch 367/500\n",
      "320/320 - 0s - loss: 1.2480e-06 - acc: 1.0000 - val_loss: 1.8676 - val_acc: 0.8544\n",
      "Epoch 368/500\n",
      "320/320 - 0s - loss: 1.2327e-06 - acc: 1.0000 - val_loss: 1.8688 - val_acc: 0.8544\n",
      "Epoch 369/500\n",
      "320/320 - 0s - loss: 1.2267e-06 - acc: 1.0000 - val_loss: 1.8697 - val_acc: 0.8544\n",
      "Epoch 370/500\n",
      "320/320 - 0s - loss: 1.2170e-06 - acc: 1.0000 - val_loss: 1.8722 - val_acc: 0.8481\n",
      "Epoch 371/500\n",
      "320/320 - 0s - loss: 1.2074e-06 - acc: 1.0000 - val_loss: 1.8735 - val_acc: 0.8481\n",
      "Epoch 372/500\n",
      "320/320 - 0s - loss: 1.1954e-06 - acc: 1.0000 - val_loss: 1.8749 - val_acc: 0.8481\n",
      "Epoch 373/500\n",
      "320/320 - 0s - loss: 1.1861e-06 - acc: 1.0000 - val_loss: 1.8760 - val_acc: 0.8481\n",
      "Epoch 374/500\n",
      "320/320 - 0s - loss: 1.1779e-06 - acc: 1.0000 - val_loss: 1.8767 - val_acc: 0.8544\n",
      "Epoch 375/500\n",
      "320/320 - 0s - loss: 1.1682e-06 - acc: 1.0000 - val_loss: 1.8783 - val_acc: 0.8544\n",
      "Epoch 376/500\n",
      "320/320 - 0s - loss: 1.1593e-06 - acc: 1.0000 - val_loss: 1.8802 - val_acc: 0.8481\n",
      "Epoch 377/500\n",
      "320/320 - 0s - loss: 1.1511e-06 - acc: 1.0000 - val_loss: 1.8806 - val_acc: 0.8544\n",
      "Epoch 378/500\n",
      "320/320 - 0s - loss: 1.1407e-06 - acc: 1.0000 - val_loss: 1.8826 - val_acc: 0.8481\n",
      "Epoch 379/500\n",
      "320/320 - 0s - loss: 1.1347e-06 - acc: 1.0000 - val_loss: 1.8837 - val_acc: 0.8544\n",
      "Epoch 380/500\n",
      "320/320 - 0s - loss: 1.1247e-06 - acc: 1.0000 - val_loss: 1.8852 - val_acc: 0.8481\n",
      "Epoch 381/500\n",
      "320/320 - 0s - loss: 1.1157e-06 - acc: 1.0000 - val_loss: 1.8870 - val_acc: 0.8481\n",
      "Epoch 382/500\n",
      "320/320 - 0s - loss: 1.1064e-06 - acc: 1.0000 - val_loss: 1.8880 - val_acc: 0.8481\n",
      "Epoch 383/500\n",
      "320/320 - 0s - loss: 1.0990e-06 - acc: 1.0000 - val_loss: 1.8892 - val_acc: 0.8481\n",
      "Epoch 384/500\n",
      "320/320 - 0s - loss: 1.0915e-06 - acc: 1.0000 - val_loss: 1.8903 - val_acc: 0.8544\n",
      "Epoch 385/500\n",
      "320/320 - 0s - loss: 1.0855e-06 - acc: 1.0000 - val_loss: 1.8921 - val_acc: 0.8481\n",
      "Epoch 386/500\n",
      "320/320 - 0s - loss: 1.0736e-06 - acc: 1.0000 - val_loss: 1.8931 - val_acc: 0.8544\n",
      "Epoch 387/500\n",
      "320/320 - 0s - loss: 1.0647e-06 - acc: 1.0000 - val_loss: 1.8942 - val_acc: 0.8544\n",
      "Epoch 388/500\n",
      "320/320 - 0s - loss: 1.0583e-06 - acc: 1.0000 - val_loss: 1.8958 - val_acc: 0.8481\n",
      "Epoch 389/500\n",
      "320/320 - 0s - loss: 1.0535e-06 - acc: 1.0000 - val_loss: 1.8960 - val_acc: 0.8544\n",
      "Epoch 390/500\n",
      "320/320 - 0s - loss: 1.0431e-06 - acc: 1.0000 - val_loss: 1.8979 - val_acc: 0.8544\n",
      "Epoch 391/500\n",
      "320/320 - 0s - loss: 1.0338e-06 - acc: 1.0000 - val_loss: 1.9000 - val_acc: 0.8481\n",
      "Epoch 392/500\n",
      "320/320 - 0s - loss: 1.0267e-06 - acc: 1.0000 - val_loss: 1.9018 - val_acc: 0.8481\n",
      "Epoch 393/500\n",
      "320/320 - 0s - loss: 1.0181e-06 - acc: 1.0000 - val_loss: 1.9025 - val_acc: 0.8481\n",
      "Epoch 394/500\n",
      "320/320 - 0s - loss: 1.0099e-06 - acc: 1.0000 - val_loss: 1.9032 - val_acc: 0.8544\n",
      "Epoch 395/500\n",
      "320/320 - 0s - loss: 1.0040e-06 - acc: 1.0000 - val_loss: 1.9046 - val_acc: 0.8481\n",
      "Epoch 396/500\n",
      "320/320 - 0s - loss: 9.9614e-07 - acc: 1.0000 - val_loss: 1.9058 - val_acc: 0.8544\n",
      "Epoch 397/500\n",
      "320/320 - 0s - loss: 9.8794e-07 - acc: 1.0000 - val_loss: 1.9072 - val_acc: 0.8481\n",
      "Epoch 398/500\n",
      "320/320 - 0s - loss: 9.8384e-07 - acc: 1.0000 - val_loss: 1.9090 - val_acc: 0.8481\n",
      "Epoch 399/500\n",
      "320/320 - 0s - loss: 9.7453e-07 - acc: 1.0000 - val_loss: 1.9096 - val_acc: 0.8544\n",
      "Epoch 400/500\n",
      "320/320 - 0s - loss: 9.6671e-07 - acc: 1.0000 - val_loss: 1.9110 - val_acc: 0.8544\n",
      "Epoch 401/500\n",
      "320/320 - 0s - loss: 9.5814e-07 - acc: 1.0000 - val_loss: 1.9126 - val_acc: 0.8481\n",
      "Epoch 402/500\n",
      "320/320 - 0s - loss: 9.5181e-07 - acc: 1.0000 - val_loss: 1.9144 - val_acc: 0.8481\n",
      "Epoch 403/500\n",
      "320/320 - 0s - loss: 9.4510e-07 - acc: 1.0000 - val_loss: 1.9151 - val_acc: 0.8481\n",
      "Epoch 404/500\n",
      "320/320 - 0s - loss: 9.4026e-07 - acc: 1.0000 - val_loss: 1.9155 - val_acc: 0.8544\n",
      "Epoch 405/500\n",
      "320/320 - 0s - loss: 9.3132e-07 - acc: 1.0000 - val_loss: 1.9171 - val_acc: 0.8544\n",
      "Epoch 406/500\n",
      "320/320 - 0s - loss: 9.2312e-07 - acc: 1.0000 - val_loss: 1.9184 - val_acc: 0.8544\n",
      "Epoch 407/500\n",
      "320/320 - 0s - loss: 9.1567e-07 - acc: 1.0000 - val_loss: 1.9204 - val_acc: 0.8481\n",
      "Epoch 408/500\n",
      "320/320 - 0s - loss: 9.1008e-07 - acc: 1.0000 - val_loss: 1.9220 - val_acc: 0.8481\n",
      "Epoch 409/500\n",
      "320/320 - 0s - loss: 9.0301e-07 - acc: 1.0000 - val_loss: 1.9235 - val_acc: 0.8481\n",
      "Epoch 410/500\n",
      "320/320 - 0s - loss: 8.9667e-07 - acc: 1.0000 - val_loss: 1.9246 - val_acc: 0.8481\n",
      "Epoch 411/500\n",
      "320/320 - 0s - loss: 8.9034e-07 - acc: 1.0000 - val_loss: 1.9261 - val_acc: 0.8481\n",
      "Epoch 412/500\n",
      "320/320 - 0s - loss: 8.8438e-07 - acc: 1.0000 - val_loss: 1.9263 - val_acc: 0.8481\n",
      "Epoch 413/500\n",
      "320/320 - 0s - loss: 8.7767e-07 - acc: 1.0000 - val_loss: 1.9272 - val_acc: 0.8544\n",
      "Epoch 414/500\n",
      "320/320 - 0s - loss: 8.7171e-07 - acc: 1.0000 - val_loss: 1.9292 - val_acc: 0.8481\n",
      "Epoch 415/500\n",
      "320/320 - 0s - loss: 8.6613e-07 - acc: 1.0000 - val_loss: 1.9298 - val_acc: 0.8481\n",
      "Epoch 416/500\n",
      "320/320 - 0s - loss: 8.5644e-07 - acc: 1.0000 - val_loss: 1.9316 - val_acc: 0.8481\n",
      "Epoch 417/500\n",
      "320/320 - 0s - loss: 8.4936e-07 - acc: 1.0000 - val_loss: 1.9325 - val_acc: 0.8481\n",
      "Epoch 418/500\n",
      "320/320 - 0s - loss: 8.4452e-07 - acc: 1.0000 - val_loss: 1.9350 - val_acc: 0.8481\n",
      "Epoch 419/500\n",
      "320/320 - 0s - loss: 8.3707e-07 - acc: 1.0000 - val_loss: 1.9353 - val_acc: 0.8481\n",
      "Epoch 420/500\n",
      "320/320 - 0s - loss: 8.3036e-07 - acc: 1.0000 - val_loss: 1.9365 - val_acc: 0.8481\n",
      "Epoch 421/500\n",
      "320/320 - 0s - loss: 8.2440e-07 - acc: 1.0000 - val_loss: 1.9375 - val_acc: 0.8481\n",
      "Epoch 422/500\n",
      "320/320 - 0s - loss: 8.1807e-07 - acc: 1.0000 - val_loss: 1.9393 - val_acc: 0.8481\n",
      "Epoch 423/500\n",
      "320/320 - 0s - loss: 8.1211e-07 - acc: 1.0000 - val_loss: 1.9403 - val_acc: 0.8481\n",
      "Epoch 424/500\n",
      "320/320 - 0s - loss: 8.0652e-07 - acc: 1.0000 - val_loss: 1.9413 - val_acc: 0.8481\n",
      "Epoch 425/500\n",
      "320/320 - 0s - loss: 8.0056e-07 - acc: 1.0000 - val_loss: 1.9423 - val_acc: 0.8481\n",
      "Epoch 426/500\n",
      "320/320 - 0s - loss: 7.9497e-07 - acc: 1.0000 - val_loss: 1.9443 - val_acc: 0.8481\n",
      "Epoch 427/500\n",
      "320/320 - 0s - loss: 7.9162e-07 - acc: 1.0000 - val_loss: 1.9454 - val_acc: 0.8481\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 428/500\n",
      "320/320 - 0s - loss: 7.8491e-07 - acc: 1.0000 - val_loss: 1.9465 - val_acc: 0.8481\n",
      "Epoch 429/500\n",
      "320/320 - 0s - loss: 7.8044e-07 - acc: 1.0000 - val_loss: 1.9473 - val_acc: 0.8481\n",
      "Epoch 430/500\n",
      "320/320 - 0s - loss: 7.7262e-07 - acc: 1.0000 - val_loss: 1.9491 - val_acc: 0.8481\n",
      "Epoch 431/500\n",
      "320/320 - 0s - loss: 7.6703e-07 - acc: 1.0000 - val_loss: 1.9504 - val_acc: 0.8481\n",
      "Epoch 432/500\n",
      "320/320 - 0s - loss: 7.6405e-07 - acc: 1.0000 - val_loss: 1.9517 - val_acc: 0.8481\n",
      "Epoch 433/500\n",
      "320/320 - 0s - loss: 7.5772e-07 - acc: 1.0000 - val_loss: 1.9526 - val_acc: 0.8481\n",
      "Epoch 434/500\n",
      "320/320 - 0s - loss: 7.5325e-07 - acc: 1.0000 - val_loss: 1.9536 - val_acc: 0.8481\n",
      "Epoch 435/500\n",
      "320/320 - 0s - loss: 7.4803e-07 - acc: 1.0000 - val_loss: 1.9551 - val_acc: 0.8481\n",
      "Epoch 436/500\n",
      "320/320 - 0s - loss: 7.4096e-07 - acc: 1.0000 - val_loss: 1.9568 - val_acc: 0.8481\n",
      "Epoch 437/500\n",
      "320/320 - 0s - loss: 7.3649e-07 - acc: 1.0000 - val_loss: 1.9576 - val_acc: 0.8481\n",
      "Epoch 438/500\n",
      "320/320 - 0s - loss: 7.2978e-07 - acc: 1.0000 - val_loss: 1.9588 - val_acc: 0.8481\n",
      "Epoch 439/500\n",
      "320/320 - 0s - loss: 7.2382e-07 - acc: 1.0000 - val_loss: 1.9605 - val_acc: 0.8481\n",
      "Epoch 440/500\n",
      "320/320 - 0s - loss: 7.1935e-07 - acc: 1.0000 - val_loss: 1.9612 - val_acc: 0.8481\n",
      "Epoch 441/500\n",
      "320/320 - 0s - loss: 7.1451e-07 - acc: 1.0000 - val_loss: 1.9631 - val_acc: 0.8481\n",
      "Epoch 442/500\n",
      "320/320 - 0s - loss: 7.0892e-07 - acc: 1.0000 - val_loss: 1.9639 - val_acc: 0.8481\n",
      "Epoch 443/500\n",
      "320/320 - 0s - loss: 7.0668e-07 - acc: 1.0000 - val_loss: 1.9643 - val_acc: 0.8481\n",
      "Epoch 444/500\n",
      "320/320 - 0s - loss: 7.0072e-07 - acc: 1.0000 - val_loss: 1.9661 - val_acc: 0.8481\n",
      "Epoch 445/500\n",
      "320/320 - 0s - loss: 6.9625e-07 - acc: 1.0000 - val_loss: 1.9680 - val_acc: 0.8481\n",
      "Epoch 446/500\n",
      "320/320 - 0s - loss: 6.8918e-07 - acc: 1.0000 - val_loss: 1.9683 - val_acc: 0.8481\n",
      "Epoch 447/500\n",
      "320/320 - 0s - loss: 6.8359e-07 - acc: 1.0000 - val_loss: 1.9693 - val_acc: 0.8481\n",
      "Epoch 448/500\n",
      "320/320 - 0s - loss: 6.7725e-07 - acc: 1.0000 - val_loss: 1.9703 - val_acc: 0.8481\n",
      "Epoch 449/500\n",
      "320/320 - 0s - loss: 6.7316e-07 - acc: 1.0000 - val_loss: 1.9720 - val_acc: 0.8481\n",
      "Epoch 450/500\n",
      "320/320 - 0s - loss: 6.6906e-07 - acc: 1.0000 - val_loss: 1.9731 - val_acc: 0.8481\n",
      "Epoch 451/500\n",
      "320/320 - 0s - loss: 6.6571e-07 - acc: 1.0000 - val_loss: 1.9749 - val_acc: 0.8481\n",
      "Epoch 452/500\n",
      "320/320 - 0s - loss: 6.5900e-07 - acc: 1.0000 - val_loss: 1.9765 - val_acc: 0.8481\n",
      "Epoch 453/500\n",
      "320/320 - 0s - loss: 6.5379e-07 - acc: 1.0000 - val_loss: 1.9770 - val_acc: 0.8481\n",
      "Epoch 454/500\n",
      "320/320 - 0s - loss: 6.5081e-07 - acc: 1.0000 - val_loss: 1.9781 - val_acc: 0.8481\n",
      "Epoch 455/500\n",
      "320/320 - 0s - loss: 6.4634e-07 - acc: 1.0000 - val_loss: 1.9786 - val_acc: 0.8481\n",
      "Epoch 456/500\n",
      "320/320 - 0s - loss: 6.4224e-07 - acc: 1.0000 - val_loss: 1.9799 - val_acc: 0.8481\n",
      "Epoch 457/500\n",
      "320/320 - 0s - loss: 6.3777e-07 - acc: 1.0000 - val_loss: 1.9823 - val_acc: 0.8481\n",
      "Epoch 458/500\n",
      "320/320 - 0s - loss: 6.3404e-07 - acc: 1.0000 - val_loss: 1.9831 - val_acc: 0.8481\n",
      "Epoch 459/500\n",
      "320/320 - 0s - loss: 6.3069e-07 - acc: 1.0000 - val_loss: 1.9839 - val_acc: 0.8481\n",
      "Epoch 460/500\n",
      "320/320 - 0s - loss: 6.2398e-07 - acc: 1.0000 - val_loss: 1.9851 - val_acc: 0.8481\n",
      "Epoch 461/500\n",
      "320/320 - 0s - loss: 6.2100e-07 - acc: 1.0000 - val_loss: 1.9874 - val_acc: 0.8481\n",
      "Epoch 462/500\n",
      "320/320 - 0s - loss: 6.1616e-07 - acc: 1.0000 - val_loss: 1.9880 - val_acc: 0.8481\n",
      "Epoch 463/500\n",
      "320/320 - 0s - loss: 6.1355e-07 - acc: 1.0000 - val_loss: 1.9889 - val_acc: 0.8481\n",
      "Epoch 464/500\n",
      "320/320 - 0s - loss: 6.0648e-07 - acc: 1.0000 - val_loss: 1.9897 - val_acc: 0.8481\n",
      "Epoch 465/500\n",
      "320/320 - 0s - loss: 6.0349e-07 - acc: 1.0000 - val_loss: 1.9911 - val_acc: 0.8481\n",
      "Epoch 466/500\n",
      "320/320 - 0s - loss: 5.9940e-07 - acc: 1.0000 - val_loss: 1.9925 - val_acc: 0.8481\n",
      "Epoch 467/500\n",
      "320/320 - 0s - loss: 5.9493e-07 - acc: 1.0000 - val_loss: 1.9934 - val_acc: 0.8481\n",
      "Epoch 468/500\n",
      "320/320 - 0s - loss: 5.8971e-07 - acc: 1.0000 - val_loss: 1.9948 - val_acc: 0.8481\n",
      "Epoch 469/500\n",
      "320/320 - 0s - loss: 5.8450e-07 - acc: 1.0000 - val_loss: 1.9960 - val_acc: 0.8481\n",
      "Epoch 470/500\n",
      "320/320 - 0s - loss: 5.8189e-07 - acc: 1.0000 - val_loss: 1.9971 - val_acc: 0.8481\n",
      "Epoch 471/500\n",
      "320/320 - 0s - loss: 5.7593e-07 - acc: 1.0000 - val_loss: 1.9987 - val_acc: 0.8481\n",
      "Epoch 472/500\n",
      "320/320 - 0s - loss: 5.7332e-07 - acc: 1.0000 - val_loss: 2.0000 - val_acc: 0.8481\n",
      "Epoch 473/500\n",
      "320/320 - 0s - loss: 5.6922e-07 - acc: 1.0000 - val_loss: 2.0007 - val_acc: 0.8481\n",
      "Epoch 474/500\n",
      "320/320 - 0s - loss: 5.6624e-07 - acc: 1.0000 - val_loss: 2.0018 - val_acc: 0.8481\n",
      "Epoch 475/500\n",
      "320/320 - 0s - loss: 5.6214e-07 - acc: 1.0000 - val_loss: 2.0024 - val_acc: 0.8481\n",
      "Epoch 476/500\n",
      "320/320 - 0s - loss: 5.5805e-07 - acc: 1.0000 - val_loss: 2.0043 - val_acc: 0.8481\n",
      "Epoch 477/500\n",
      "320/320 - 0s - loss: 5.5432e-07 - acc: 1.0000 - val_loss: 2.0053 - val_acc: 0.8481\n",
      "Epoch 478/500\n",
      "320/320 - 0s - loss: 5.5097e-07 - acc: 1.0000 - val_loss: 2.0067 - val_acc: 0.8481\n",
      "Epoch 479/500\n",
      "320/320 - 0s - loss: 5.4724e-07 - acc: 1.0000 - val_loss: 2.0082 - val_acc: 0.8481\n",
      "Epoch 480/500\n",
      "320/320 - 0s - loss: 5.4277e-07 - acc: 1.0000 - val_loss: 2.0088 - val_acc: 0.8481\n",
      "Epoch 481/500\n",
      "320/320 - 0s - loss: 5.3979e-07 - acc: 1.0000 - val_loss: 2.0095 - val_acc: 0.8481\n",
      "Epoch 482/500\n",
      "320/320 - 0s - loss: 5.3607e-07 - acc: 1.0000 - val_loss: 2.0107 - val_acc: 0.8481\n",
      "Epoch 483/500\n",
      "320/320 - 0s - loss: 5.3197e-07 - acc: 1.0000 - val_loss: 2.0122 - val_acc: 0.8481\n",
      "Epoch 484/500\n",
      "320/320 - 0s - loss: 5.3011e-07 - acc: 1.0000 - val_loss: 2.0136 - val_acc: 0.8481\n",
      "Epoch 485/500\n",
      "320/320 - 0s - loss: 5.2452e-07 - acc: 1.0000 - val_loss: 2.0151 - val_acc: 0.8481\n",
      "Epoch 486/500\n",
      "320/320 - 0s - loss: 5.2154e-07 - acc: 1.0000 - val_loss: 2.0166 - val_acc: 0.8481\n",
      "Epoch 487/500\n",
      "320/320 - 0s - loss: 5.1856e-07 - acc: 1.0000 - val_loss: 2.0176 - val_acc: 0.8481\n",
      "Epoch 488/500\n",
      "320/320 - 0s - loss: 5.1372e-07 - acc: 1.0000 - val_loss: 2.0180 - val_acc: 0.8481\n",
      "Epoch 489/500\n",
      "320/320 - 0s - loss: 5.0999e-07 - acc: 1.0000 - val_loss: 2.0189 - val_acc: 0.8481\n",
      "Epoch 490/500\n",
      "320/320 - 0s - loss: 5.0701e-07 - acc: 1.0000 - val_loss: 2.0203 - val_acc: 0.8481\n",
      "Epoch 491/500\n",
      "320/320 - 0s - loss: 5.0478e-07 - acc: 1.0000 - val_loss: 2.0218 - val_acc: 0.8481\n",
      "Epoch 492/500\n",
      "320/320 - 0s - loss: 4.9993e-07 - acc: 1.0000 - val_loss: 2.0231 - val_acc: 0.8481\n",
      "Epoch 493/500\n",
      "320/320 - 0s - loss: 4.9695e-07 - acc: 1.0000 - val_loss: 2.0243 - val_acc: 0.8481\n",
      "Epoch 494/500\n",
      "320/320 - 0s - loss: 4.9397e-07 - acc: 1.0000 - val_loss: 2.0247 - val_acc: 0.8481\n",
      "Epoch 495/500\n",
      "320/320 - 0s - loss: 4.8987e-07 - acc: 1.0000 - val_loss: 2.0267 - val_acc: 0.8481\n",
      "Epoch 496/500\n",
      "320/320 - 0s - loss: 4.8578e-07 - acc: 1.0000 - val_loss: 2.0275 - val_acc: 0.8481\n",
      "Epoch 497/500\n",
      "320/320 - 0s - loss: 4.8093e-07 - acc: 1.0000 - val_loss: 2.0283 - val_acc: 0.8481\n",
      "Epoch 498/500\n",
      "320/320 - 0s - loss: 4.7870e-07 - acc: 1.0000 - val_loss: 2.0299 - val_acc: 0.8481\n",
      "Epoch 499/500\n",
      "320/320 - 0s - loss: 4.7721e-07 - acc: 1.0000 - val_loss: 2.0317 - val_acc: 0.8481\n",
      "Epoch 500/500\n",
      "320/320 - 0s - loss: 4.7386e-07 - acc: 1.0000 - val_loss: 2.0328 - val_acc: 0.8481\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1c94e5dfe48>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train_categorical,\n",
    "    validation_data=(X_test_scaled, y_test_categorical),\n",
    "    epochs=500,\n",
    "    shuffle=True,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantify our Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "158/158 - 0s - loss: 2.0328 - acc: 0.8481\n",
      "Normal Neural Network - Loss: 2.032788979856274, Accuracy: 0.8481012582778931\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = model.evaluate(\n",
    "    X_test_scaled, y_test_categorical, verbose=2)\n",
    "print(\n",
    "    f\"Normal Neural Network - Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f97eb3e97245187b",
     "locked": false,
     "schema_version": 1,
     "solution": true
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "encoded_predictions = model.predict_classes(X_test_scaled[:2])\n",
    "prediction_labels = label_encoder.inverse_transform(encoded_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted classes: [0. 0.]\n",
      "Actual Labels: [0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Predicted classes: {prediction_labels}\")\n",
    "print(f\"Actual Labels: {list(y_test[:2])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 0],\n",
       "       [1, 1]], dtype=int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "y_true = y_test[:5]\n",
    "y_pred = prediction_labels\n",
    "confusion_matrix(y_true, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5454545454545454"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import cohen_kappa_score\n",
    "y_true = y_test[:5]\n",
    "y_pred = prediction_labels\n",
    "cohen_kappa_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict_classes(X_test_scaled)\n",
    "labels = label_encoder.inverse_transform(predictions)\n",
    "actual = list(labels)\n",
    "predicted = list(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[86,  7],\n",
       "       [17, 48]], dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "y_true = actual\n",
    "y_pred = predicted\n",
    "confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "class 0 - false       0.83      0.92      0.88        93\n",
      " class 1 - true       0.87      0.74      0.80        65\n",
      "\n",
      "       accuracy                           0.85       158\n",
      "      macro avg       0.85      0.83      0.84       158\n",
      "   weighted avg       0.85      0.85      0.85       158\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "y_true = actual\n",
    "y_pred = predicted\n",
    "target_names = ['class 0 - false', 'class 1 - true']\n",
    "print(classification_report(y_true, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the SVC Model\n",
    "from sklearn.svm import SVC \n",
    "model2 = SVC(kernel='linear')\n",
    "model2.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Create the GridSearchCV model\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'C': [1, 5, 10, 50],\n",
    "              'gamma': [0.0001, 0.0005, 0.001, 0.005]}\n",
    "grid = GridSearchCV(model2, param_grid, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model with GridSearch\n",
    "grid.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid.best_params_)\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import accuracy_score\n",
    "# from sklearn.metrics import make_scorer\n",
    "# scoring = {'accuracy': make_scorer(accuracy_score),\n",
    "#             'prec': 'precision'}\n",
    "# scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = grid.cv_results_\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "scoring = {'AUC': 'roc_auc', 'Accuracy': make_scorer(accuracy_score)}\n",
    "\n",
    "gs = GridSearchCV(DecisionTreeClassifier(random_state=42),\n",
    "                  param_grid={'min_samples_split': range(2, 403, 10)},\n",
    "                  scoring=scoring, refit='AUC', return_train_score=True)\n",
    "gs.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = gs.cv_results_\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gs.best_params_)\n",
    "print(gs.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.predict_log_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.get_params(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
